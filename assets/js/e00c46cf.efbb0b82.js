"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5654],{28453:(e,i,n)=>{n.d(i,{R:()=>a,x:()=>t});var r=n(96540);const s={},l=r.createContext(s);function a(e){const i=r.useContext(l);return r.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function t(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(l.Provider,{value:i},e.children)}},38070:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>o,contentTitle:()=>t,default:()=>p,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"system-design/building-realtime-video-processing-applications","title":"Building Real-Time Video Processing Applications","description":"building realtime video processing applications","source":"@site/../../docs/system-design/building-realtime-video-processing-applications.mdx","sourceDirName":"system-design","slug":"/system-design/building-realtime-video-processing-applications","permalink":"/docs/system-design/building-realtime-video-processing-applications","draft":false,"unlisted":false,"editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/docs/../../docs/system-design/building-realtime-video-processing-applications.mdx","tags":[{"inline":true,"label":"ml","permalink":"/docs/tags/ml"},{"inline":true,"label":"system-design","permalink":"/docs/tags/system-design"},{"inline":true,"label":"video","permalink":"/docs/tags/video"}],"version":"current","lastUpdatedBy":"frank","lastUpdatedAt":1744416000000,"frontMatter":{"sidebar_label":"building realtime video processing applications","description":"building realtime video processing applications","keywords":["system-design","video","ml"],"image":"https://i.imgur.com/mErPwqL.png","tags":["ml","system-design","video"],"last_update":{"date":"2025-04-12T00:00:00.000Z","author":"frank"}},"sidebar":"docs","previous":{"title":"building etl in ml with Airflow","permalink":"/docs/system-design/building-etl-in-ml-with-airflow"},"next":{"title":"designing-tiktok-comment-threads","permalink":"/docs/system-design/designing-tiktok-comment-threads"}}');var s=n(74848),l=n(28453);const a={sidebar_label:"building realtime video processing applications",description:"building realtime video processing applications",keywords:["system-design","video","ml"],image:"https://i.imgur.com/mErPwqL.png",tags:["ml","system-design","video"],last_update:{date:new Date("2025-04-12T00:00:00.000Z"),author:"frank"}},t="Building Real-Time Video Processing Applications",o={},d=[{value:"What Is Real-Time Video Processing?",id:"what-is-real-time-video-processing",level:2},{value:"Data Pipeline Architecture",id:"data-pipeline-architecture",level:2},{value:"1. The Custom Approach: Building a Native Android Pipeline",id:"1-the-custom-approach-building-a-native-android-pipeline",level:2},{value:"2. The Framework-Based Approach: Using GUI Frameworks Like Unity or Qt",id:"2-the-framework-based-approach-using-gui-frameworks-like-unity-or-qt",level:2},{value:"Why Use a Framework?",id:"why-use-a-framework",level:2},{value:"Conclusion",id:"conclusion",level:2}];function c(e){const i={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"building-real-time-video-processing-applications",children:"Building Real-Time Video Processing Applications"})}),"\n",(0,s.jsx)(i.p,{children:"In recent years, real-time video processing has become an essential component in consumer and industrial applications\u2014ranging from pose detection and AR effects to equipment monitoring and telehealth systems. While it\u2019s common to start with platform-specific solutions (such as native Android pipelines), this path can quickly lead to complexity and duplication of work when targeting multiple platforms like iOS, desktop, or embedded systems."}),"\n",(0,s.jsx)(i.p,{children:"In this blog, I\u2019ll walk through the two primary approaches to building real-time video processing pipelines:"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsx)(i.li,{children:"Custom implementation using platform-native libraries (e.g., Android)"}),"\n",(0,s.jsx)(i.li,{children:"Cross-platform implementation using GUI frameworks (e.g., Unity, Qt)"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"We\u2019ll discuss basic architecture for real-time video processing, and how GUI frameworks can significantly reduce the engineering effort for cross-platform deployments."}),"\n",(0,s.jsx)(i.h2,{id:"what-is-real-time-video-processing",children:"What Is Real-Time Video Processing?"}),"\n",(0,s.jsx)(i.p,{children:"Real-time video processing refers to capturing, analyzing(ML model), and rendering video frames fast enough that users perceive the experience as immediate \u2014 typically at 30/60 FPS or higher. Basically, this involves a video/data pipeline that:"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsx)(i.li,{children:"Captures video frames from camera"}),"\n",(0,s.jsx)(i.li,{children:"Processes them (e.g., AI inference),"}),"\n",(0,s.jsx)(i.li,{children:"Renders the processed results like drawing annotations, etc."}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"To ensure a smooth performance for user experiences, multiple threads programming and buffering are critical tech stacks among the implementation for real-time."}),"\n",(0,s.jsx)(i.p,{children:"This is a modular approach where developers manually control each stage:"}),"\n",(0,s.jsx)(i.h2,{id:"data-pipeline-architecture",children:"Data Pipeline Architecture"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-sh",children:"[Video Capture(v4l2, DirectShow)]\n      \u2193\n[ML Model (Analyze)]\n      \u2193\n[Render (Overlay)]\n"})}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["Video Capture","\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Use low-level OS interfaces like v4l2(Linux), DirectShow(Windows) or multimedia libraries like GStreamer, FFmpeg, OpenCV, CameraX."}),"\n",(0,s.jsx)(i.li,{children:"Deliver video frames as RGB from YUV_420_888 format OpenCV, optionally in the regard of ML model input image format supports."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["ML Model Analysis","\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Use ML model for face detection, object detection, or pose estimation."}),"\n",(0,s.jsx)(i.li,{children:"ML model returns results like keypoints, bounding boxes, and confidence scores."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["Rendering","\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Use Skia, OpenGL, or libraries to draw bounding boxes, etc."}),"\n",(0,s.jsx)(i.li,{children:"You must manually draw overlays using model output."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"1-the-custom-approach-building-a-native-android-pipeline",children:"1. The Custom Approach: Building a Native Android Pipeline"}),"\n",(0,s.jsx)(i.p,{children:"When building a real-time video processing app on Android, developers typically stitch together multiple libraries to handle video capture, AI inference, rendering, and user interaction. Here\u2019s an example stack:"}),"\n",(0,s.jsx)(i.p,{children:"Typical Android Pipeline:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Video Capture: CameraX"}),"\n",(0,s.jsx)(i.li,{children:"AI Processing: ML Kit, TensorFlow Lite, or custom JNI wrappers"}),"\n",(0,s.jsx)(i.li,{children:"Frame Conversion: YUV to RGB via RenderScript or GPU"}),"\n",(0,s.jsx)(i.li,{children:"Rendering: Canvas, SurfaceView, or OpenGL ES"}),"\n",(0,s.jsx)(i.li,{children:"UI Layer: XML layouts + Jetpack Compose"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"This custom pipeline offers maximum control, but it also comes with challenges:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"You must manually handle format conversion (YUV to RGB, etc.)"}),"\n",(0,s.jsx)(i.li,{children:"You must synchronize frame timing between components"}),"\n",(0,s.jsx)(i.li,{children:"Each platform (iOS, Windows, macOS) requires a completely different implementation"}),"\n",(0,s.jsx)(i.li,{children:"Performance tuning is low-level and platform-specific"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Bottom line: Great flexibility, but high development and maintenance cost."}),"\n",(0,s.jsx)(i.h2,{id:"2-the-framework-based-approach-using-gui-frameworks-like-unity-or-qt",children:"2. The Framework-Based Approach: Using GUI Frameworks Like Unity or Qt"}),"\n",(0,s.jsx)(i.p,{children:"Instead of re-implementing pipelines per platform, GUI frameworks like Unity and Qt provide a cross-platform abstraction layer over hardware, video capture, GPU rendering, and AI integration."}),"\n",(0,s.jsx)(i.p,{children:"These frameworks wrap native APIs (e.g., Android Camera2, iOS AVFoundation) and offer built-in rendering pipelines, which means you can focus on application logic and user experience."}),"\n",(0,s.jsx)(i.p,{children:"Typical Unity Pipeline:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Capture: WebCamTexture (auto-handles Android/iOS differences)"}),"\n",(0,s.jsx)(i.li,{children:"AI Processing: Barracuda, TFLite Plugin, or MediaPipe Unity Plugin"}),"\n",(0,s.jsx)(i.li,{children:"Rendering: GPU-accelerated overlay using Canvas, Shaders, or 3D objects"}),"\n",(0,s.jsx)(i.li,{children:"UI Layer: Unity UI + C#"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Typical Qt Pipeline:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Capture: QCamera + GStreamer or OpenCV backend"}),"\n",(0,s.jsx)(i.li,{children:"AI Processing: TensorFlow Lite, ONNX, or OpenCV DNN module"}),"\n",(0,s.jsx)(i.li,{children:"Rendering: QML, QPainter, or OpenGL"}),"\n",(0,s.jsx)(i.li,{children:"UI Layer: QML + C++"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Bottom line: Frameworks reduce effort and increase portability \u2014 ideal for fast product development."}),"\n",(0,s.jsx)(i.h2,{id:"why-use-a-framework",children:"Why Use a Framework?"}),"\n",(0,s.jsx)(i.p,{children:"Pros:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Cross-platform out of the box"}),"\n",(0,s.jsx)(i.li,{children:"Hardware acceleration built-in"}),"\n",(0,s.jsx)(i.li,{children:"Clean separation between logic and rendering"}),"\n",(0,s.jsx)(i.li,{children:"Reusable codebase and assets"}),"\n",(0,s.jsx)(i.li,{children:"Easier to integrate with AR/VR or gaming features"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Cons:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Some frameworks abstract too much \u2014 not ideal for edge cases"}),"\n",(0,s.jsx)(i.li,{children:"Slightly more overhead than bare-metal native code"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsx)(i.p,{children:"If you\u2019re aiming to develop a real-time video processing application that works across multiple platforms, cross-platform GUI frameworks like Unity or Qt are powerful tools that can save you months of engineering time."}),"\n",(0,s.jsx)(i.p,{children:"They provide:"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Built-in hardware acceleration"}),"\n",(0,s.jsx)(i.li,{children:"Unified APIs for camera and rendering"}),"\n",(0,s.jsx)(i.li,{children:"Portability across mobile and desktop"}),"\n"]}),"\n",(0,s.jsx)(i.p,{children:"Of course, native pipelines are still valuable when you need absolute performance or deep platform integration\u2014but for most modern applications, frameworks like Unity strike the right balance between flexibility and development speed."})]})}function p(e={}){const{wrapper:i}={...(0,l.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);