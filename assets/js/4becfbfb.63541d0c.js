"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7065],{17420:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>r,contentTitle:()=>l,default:()=>m,frontMatter:()=>o,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"system-design/building-etl-in-ml-with-airflow","title":"Building ETL Data Pipeline for ML Training with Airflow","description":"Building ETL Data Pipeline for ML Training with Airflow","source":"@site/../../docs/system-design/building-etl-in-ml-with-airflow.mdx","sourceDirName":"system-design","slug":"/system-design/building-etl-in-ml-with-airflow","permalink":"/docs/system-design/building-etl-in-ml-with-airflow","draft":false,"unlisted":false,"editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/docs/../../docs/system-design/building-etl-in-ml-with-airflow.mdx","tags":[{"inline":true,"label":"python","permalink":"/docs/tags/python"},{"inline":true,"label":"ml","permalink":"/docs/tags/ml"},{"inline":true,"label":"system-design","permalink":"/docs/tags/system-design"}],"version":"current","lastUpdatedBy":"frank","lastUpdatedAt":1739836800000,"frontMatter":{"sidebar_label":"building etl in ml with Airflow","description":"Building ETL Data Pipeline for ML Training with Airflow","keywords":["etl","ml","python","Airflow"],"image":"https://i.imgur.com/mErPwqL.png","tags":["python","ml","system-design"],"last_update":{"date":"2025-02-18T00:00:00.000Z","author":"frank"}},"sidebar":"docs","previous":{"title":"building chatgpt style conversation","permalink":"/docs/system-design/building-chatgpt-style-conversation"},"next":{"title":"building realtime video processing applications","permalink":"/docs/system-design/building-realtime-video-processing-applications"}}');var t=e(74848),s=e(28453);const o={sidebar_label:"building etl in ml with Airflow",description:"Building ETL Data Pipeline for ML Training with Airflow",keywords:["etl","ml","python","Airflow"],image:"https://i.imgur.com/mErPwqL.png",tags:["python","ml","system-design"],last_update:{date:new Date("2025-02-18T00:00:00.000Z"),author:"frank"}},l="Building ETL Data Pipeline for ML Training with Airflow",r={},d=[{value:"Project Structure",id:"project-structure",level:2},{value:"Airflow DAG: <code>ml_data_preparation_dag.py</code>",id:"airflow-dag-ml_data_preparation_dagpy",level:2},{value:"YOLOv5 Training with Python API",id:"yolov5-training-with-python-api",level:2},{value:"Airflow DAG Pipeline",id:"airflow-dag-pipeline",level:2},{value:"Results",id:"results",level:2},{value:"What\u2019s Next?",id:"whats-next",level:2}];function _(n){const i={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"building-etl-data-pipeline-for-ml-training-with-airflow",children:"Building ETL Data Pipeline for ML Training with Airflow"})}),"\n",(0,t.jsx)(i.p,{children:"In real-world machine learning workflows, preparing data and training models is rarely a one-time manual process. It's iterative, messy, and benefits immensely from automation. In this post, I\u2019ll walk you through a complete Airflow pipeline that prepares a COCO-format dataset for training and kicks off a PyTorch-based YOLOv5 training job \u2014 all locally."}),"\n",(0,t.jsx)(i.p,{children:"We'll build a clean ETL-style pipeline:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Extract"})," raw images and annotations."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Transform"})," them: resize images, update bounding boxes."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Split"})," into training and validation sets."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Train"})," a YOLOv5 object detection model using PyTorch."]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"project-structure",children:"Project Structure"}),"\n",(0,t.jsx)(i.p,{children:"Here's the expected directory layout:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-sh",children:"/raw_data/\n    images/\n        1.jpg\n        2.jpg\n    annotations.json\n"})}),"\n",(0,t.jsx)(i.p,{children:"After processing, images will be split and labeled like this:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-sh",children:"/processed_data/\n    images/\n        1.jpg\n        2.jpg\n    annotations.json\n    train/\n        images/1.jpg\n        labels/1.txt\n    val/\n        images/\n        labels/\n    yolov5_data.yaml\n"})}),"\n",(0,t.jsxs)(i.h2,{id:"airflow-dag-ml_data_preparation_dagpy",children:["Airflow DAG: ",(0,t.jsx)(i.code,{children:"ml_data_preparation_dag.py"})]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"from airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom datetime import datetime\nimport os\nimport shutil\nimport json\nfrom PIL import Image\n\nRAW_IMAGES_DIR = \"/raw_data/images\"\nRAW_ANNOTATIONS_PATH = \"/raw_data/annotations.json\"\nWORKING_IMAGES_DIR = \"/tmp/xxx_data/images\"\nWORKING_ANNOTATIONS_PATH = \"/tmp/xxx_data/annotations.json\"\nPROCESSED_DIR = \"/processed_data\"\nPROCESSED_IMAGES_DIR = os.path.join(PROCESSED_DIR, \"images\")\nPROCESSED_ANNOTATIONS_PATH = os.path.join(PROCESSED_DIR, \"annotations.json\")\nTARGET_SIZE = (416, 416)\n\nTRAIN_DIR = os.path.join(PROCESSED_DIR, \"train\")\nVAL_DIR = os.path.join(PROCESSED_DIR, \"val\")\nTRAIN_IMAGES_DIR = os.path.join(TRAIN_DIR, \"images\")\nTRAIN_LABELS_DIR = os.path.join(TRAIN_DIR, \"labels\")\nVAL_IMAGES_DIR = os.path.join(VAL_DIR, \"images\")\nVAL_LABELS_DIR = os.path.join(VAL_DIR, \"labels\")\n\nDATA_YOLO_CONFIG = os.path.join(PROCESSED_DIR, \"yolov5_data.yaml\")\n\n# Get the new data\ndef extract_data():\n    os.makedirs(WORKING_DIR, exist_ok=True)\n    os.makedirs(PROCESSED_IMAGES_DIR, exist_ok=True)\n    # Assume that I get data from local RAW_IMAGES_DIR, every time we can get new data then update it into PROCESSED_DIR\n    shutil.copy(RAW_IMAGES_DIR, WORKING_IMAGES_DIR)\n    shutil.copy(RAW_ANNOTATIONS_PATH, WORKING_ANNOTATIONS_PATH)\n\n# Resize data\ndef transform_data():\n    # Assume: the new added image filename not conflict\n    with open(WORKING_ANNOTATIONS_PATH, 'r') as f:\n        coco = json.load(f)\n\n    image_id_map = {}\n    for img in coco['images']:\n        img_path = os.path.join(WORKING_IMAGES_DIR, img['file_name'])\n        new_img_path = os.path.join(PROCESSED_IMAGES_DIR, img['file_name'])\n\n        with Image.open(img_path) as im:\n            orig_width, orig_height = im.size\n            resized = im.resize(TARGET_SIZE)\n            resized.save(new_img_path)\n\n        scale_x = TARGET_SIZE[0] / orig_width\n        scale_y = TARGET_SIZE[1] / orig_height\n\n        img['width'], img['height'] = TARGET_SIZE\n        image_id_map[img['id']] = (scale_x, scale_y)\n\n    for ann in coco['annotations']:\n        scale_x, scale_y = image_id_map[ann['image_id']]\n        x, y, w, h = ann['bbox']\n        ann['bbox'] = [\n            round(x * scale_x, 2),\n            round(y * scale_y, 2),\n            round(w * scale_x, 2),\n            round(h * scale_y, 2)\n        ]\n    \n    # Update the annotation\n    with open(PROCESSED_ANNOTATIONS_PATH, 'a') as f:\n        old_coco = json.load(f)\n        old_coco.update(coco)\n        json.dump(old_coco, f)\n\n# Add a `yolov5` compatible data\ndef load_data():\n    images_dir = PROCESSED_IMAGES_DIR\n    ann_path = PROCESSED_ANNOTATIONS_PATH\n\n    os.makedirs(TRAIN_IMAGES_DIR, exist_ok=True)\n    os.makedirs(TRAIN_LABELS_DIR, exist_ok=True)\n    os.makedirs(VAL_IMAGES_DIR, exist_ok=True)\n    os.makedirs(VAL_LABELS_DIR, exist_ok=True)\n\n    with open(ann_path) as f:\n        coco = json.load(f)\n\n    # Step 1: Build image ID to filename map\n    img_id_to_filename = {img['id']: img['file_name'] for img in coco['images']}\n\n    # Step 2: Extract classes dynamically\n    categories = {cat['id']: cat['name'] for cat in coco['categories']}\n    class_name_to_id = {v: i for i, v in enumerate(sorted(set(categories.values())))}\n    class_id_map = {cat_id: class_name_to_id[name] for cat_id, name in categories.items()}\n    class_names = list(class_name_to_id.keys())\n\n    # Step 3: Build label files in YOLO format\n    labels = {img_id: [] for img_id in img_id_to_filename}\n    for ann in coco['annotations']:\n        image_id = ann['image_id']\n        category_id = ann['category_id']\n        x, y, w, h = ann['bbox']\n        img = next(i for i in coco['images'] if i['id'] == image_id)\n        img_w, img_h = img['width'], img['height']\n        x_center = (x + w / 2) / img_w\n        y_center = (y + h / 2) / img_h\n        w /= img_w\n        h /= img_h\n        class_id = class_id_map[category_id]\n        labels[image_id].append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n\n    # Step 4: Split train/val\n    image_ids = list(img_id_to_filename.keys())\n    random.shuffle(image_ids)\n    split = int(0.8 * len(image_ids))\n    train_ids, val_ids = image_ids[:split], image_ids[split:]\n\n    for subset, subset_ids in [('train', train_ids), ('val', val_ids)]:\n        for img_id in subset_ids:\n            filename = img_id_to_filename[img_id]\n            shutil.copy(os.path.join(PROCESSED_IMAGES_DIR, filename), os.path.join(PROCESSED_DIR, subset, \"images\", filename))\n            label_path = os.path.join(PROCESSED_DIR, subset, \"labels\", f\"{Path(filename).stem}.txt\")\n            with open(label_path, 'w') as f:\n                f.write('\\n'.join(labels[img_id]))\n\n    # Step 5: Write data.yaml\n    data_yaml = {\n        'train': TRAIN_IMAGES_DIR,\n        'val': VAL_IMAGES_DIR,\n        'nc': len(class_names),\n        'names': class_names\n    }\n    with open(DATA_YOLO_CONFIG, 'w') as f:\n        yaml.dump(data_yaml, f)\n"})}),"\n",(0,t.jsx)(i.h2,{id:"yolov5-training-with-python-api",children:"YOLOv5 Training with Python API"}),"\n",(0,t.jsx)(i.p,{children:"After transformation, we split the dataset and kick off training with YOLOv5 (using the official PyTorch implementation). This step:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Extracts class names from COCO."}),"\n",(0,t.jsx)(i.li,{children:"Generates YOLO .txt label files."}),"\n",(0,t.jsx)(i.li,{children:"Splits data 80/20."}),"\n",(0,t.jsx)(i.li,{children:"Trains a model using YOLOv5\u2019s Python API."}),"\n"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-py",children:'PROCESSED_DIR = "/processed_data"\nDATA_YOLO_CONFIG = os.path.join(PROCESSED_DIR, "yolov5_data.yaml")\nTARGET_SIZE = (416, 416)\n\ndef train_model():\n    import os\n    import json\n    import shutil\n    import random\n    import yaml\n    from yolov5 import train\n\n    train.run(\n        imgsz=416,\n        batch_size=8,\n        epochs=5,\n        data=DATA_YOLO_CONFIG,\n        weights=\'yolov5s.pt\',\n        name=\'custom_yolov5_model\',\n        project=os.path.join(PROCESSED_DIR, "runs"),\n        exist_ok=True\n    )\n'})}),"\n",(0,t.jsx)(i.h2,{id:"airflow-dag-pipeline",children:"Airflow DAG Pipeline"}),"\n",(0,t.jsx)(i.p,{children:"Plug all three steps into Airflow:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-py",children:'with DAG(\n    dag_id="ml_data_preparation_dag",\n    schedule_interval=None,\n    start_date=datetime(2024, 1, 1),\n    catchup=False,\n    tags=["ml", "data-prep", "coco"]\n) as dag:\n\n    extract_task = PythonOperator(\n        task_id="extract_data",\n        python_callable=extract_data\n    )\n\n    transform_task = PythonOperator(\n        task_id="transform_data",\n        python_callable=transform_data\n    )\n\n    load_task = PythonOperator(\n        task_id="transform_data",\n        python_callable=load_data\n    )\n\n    train_task = PythonOperator(\n        task_id="train_model",\n        python_callable=train_model\n    )\n\n    extract_task >> transform_task >> load_task >> train_task\n'})}),"\n",(0,t.jsx)(i.h2,{id:"results",children:"Results"}),"\n",(0,t.jsx)(i.p,{children:"After running the DAG:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Your images and labels are properly resized and split."}),"\n",(0,t.jsx)(i.li,{children:"Your YOLOv5 model is trained with updated bounding boxes."}),"\n",(0,t.jsx)(i.li,{children:"All steps are repeatable and traceable via Airflow."}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"whats-next",children:"What\u2019s Next?"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Add evaluation and mAP tracking."}),"\n",(0,t.jsx)(i.li,{children:"Schedule retraining weekly."}),"\n",(0,t.jsx)(i.li,{children:"push trained weights to S3 or serve them with FastAPI."}),"\n"]})]})}function m(n={}){const{wrapper:i}={...(0,s.R)(),...n.components};return i?(0,t.jsx)(i,{...n,children:(0,t.jsx)(_,{...n})}):_(n)}},28453:(n,i,e)=>{e.d(i,{R:()=>o,x:()=>l});var a=e(96540);const t={},s=a.createContext(t);function o(n){const i=a.useContext(s);return a.useMemo((function(){return"function"==typeof n?n(i):{...i,...n}}),[i,n])}function l(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),a.createElement(s.Provider,{value:i},n.children)}}}]);