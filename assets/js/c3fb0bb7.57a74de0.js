"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[978],{28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var r=t(96540);const s={},o=r.createContext(s);function i(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(o.Provider,{value:n},e.children)}},59167:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var r=t(59187),s=t(74848),o=t(28453);const i={authors:["frank"],tags:["Python Celery"],description:"Python Celery",keywords:["Python Celery"],image:"https://i.imgur.com/mErPwqL.png",date:new Date("2025-04-20T00:00:00.000Z"),draft:!1,enableComments:!0},a="Orchestrating DAG-based task workflow in Celery",l={authorsImageUrls:[void 0]},c=[{value:"Construct a workflow",id:"construct-a-workflow",level:2},{value:"Avoid running synchronous subtasks within a task",id:"avoid-running-synchronous-subtasks-within-a-task",level:2},{value:"Asynchronous tasks with a task",id:"asynchronous-tasks-with-a-task",level:2},{value:"Monitor the workflow",id:"monitor-the-workflow",level:2},{value:"Resources",id:"resources",level:2}];function h(e){const n={a:"a",code:"code",h2:"h2",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(n.p,{children:["What's ",(0,s.jsx)(n.strong,{children:"workflow"})," in Celery?"]}),"\n",(0,s.jsxs)(n.p,{children:["In ",(0,s.jsx)(n.strong,{children:"Celery"}),", ",(0,s.jsx)(n.strong,{children:"workflow"})," is composed of multiple ",(0,s.jsx)(n.strong,{children:"tasks"}),", and a ",(0,s.jsx)(n.strong,{children:"task"})," is deemed to be a universal unit of the ",(0,s.jsx)(n.strong,{children:"workflow"}),", as a function in the program. In ",(0,s.jsx)(n.strong,{children:"Celery"}),", it's recommended to divide a long-running task into multiple short-running tasks. ",(0,s.jsx)(n.strong,{children:"workflow"})," comes out to help ease the orchestrations of the work, such as ",(0,s.jsx)(n.code,{children:"chain()"})," three tasks."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/liviaerxin/fastapi-celery-ml/blob/main/app/examples/celery_workflow.py",children:"A demo workflow"})}),"\n",(0,s.jsx)(n.h2,{id:"construct-a-workflow",children:"Construct a workflow"}),"\n",(0,s.jsx)(n.h2,{id:"avoid-running-synchronous-subtasks-within-a-task",children:"Avoid running synchronous subtasks within a task"}),"\n",(0,s.jsx)(n.h2,{id:"asynchronous-tasks-with-a-task",children:"Asynchronous tasks with a task"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"@app.task(bind=True)\ndef update_page_info(self, url):\n    # fetch_page -> parse_page -> store_page\n    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)\n    # chain()\n    self.replace(chain)\n\n@app.task()\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task()\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task(ignore_result=True)\ndef store_page_info(info, url):\n    PageInfo.objects.create(url=url, info=info)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"monitor-the-workflow",children:"Monitor the workflow"}),"\n",(0,s.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://blog.det.life/replacing-celery-tasks-inside-a-chain-b1328923fb02",children:"Designing Dynamic Workflows with Celery and Python | by Marin Agli\u0107 | Data Engineer Things"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://dev.to/akarshan/the-curious-case-of-celery-work-flows-39f7",children:"The Curious Case of Celery Work-flows"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://engineering.instawork.com/celery-eta-tasks-demystified-424b836e4e94",children:"Celery ETA Tasks Demystified. At Instawork, we use Celery to queue\u2026 | by Oleg Pesok | Instawork Engineering"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://docs.celeryq.dev/en/stable/userguide/canvas.html",children:"Canvas: Designing Work-flows \u2014 Celery 5.3.6 documentation"})})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},59187:e=>{e.exports=JSON.parse('{"permalink":"/blog/celery-workflow","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/celery-workflow.mdx","source":"@site/../../blog/celery-workflow.mdx","title":"Orchestrating DAG-based task workflow in Celery","description":"Python Celery","date":"2025-04-20T00:00:00.000Z","tags":[{"inline":true,"label":"Python Celery","permalink":"/blog/tags/python-celery"}],"readingTime":0.86,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["Python Celery"],"description":"Python Celery","keywords":["Python Celery"],"image":"https://i.imgur.com/mErPwqL.png","date":"2025-04-20T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","permalink":"/blog/end-to-end-ml-deployment"},"nextItem":{"title":"Lightweight CI/CD with Git Hooks and Docker Compose","permalink":"/blog/ci-cd-githook-docker"}}')}}]);