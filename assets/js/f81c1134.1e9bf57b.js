"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/end-to-end-ml-deployment","metadata":{"permalink":"/blog/end-to-end-ml-deployment","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/end-to-end-ml-deployment.mdx","source":"@site/../../blog/end-to-end-ml-deployment.mdx","title":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","description":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","date":"2025-05-10T19:12:26.000Z","tags":[{"inline":true,"label":"ml","permalink":"/blog/tags/ml"},{"inline":true,"label":"backend","permalink":"/blog/tags/backend"}],"readingTime":2.035,"hasTruncateMarker":true,"authors":[],"frontMatter":{"description":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","keywords":["ml","mlops","mlflow"],"image":"https://i.imgur.com/mErPwqL.png","tags":["ml","backend"],"last_update":{"date":"2025-05-06T00:00:00.000Z","author":"frank"}},"unlisted":false,"nextItem":{"title":"Orchestrating DAG-based task workflow in Celery","permalink":"/blog/celery-workflow"}},"content":"Deploying machine learning models is more than just training \u2014 it\u2019s about tracking, versioning, serving, and monitoring. In this post, I\u2019ll walk you through how I built a production-ready ML pipeline using:\\n\\n- **MLflow** for experiment tracking and model registry  \\n- **FastAPI** for serving models via REST API  \\n- **MinIO** for artifact storage (S3-compatible)  \\n- **Docker Compose** for orchestration  \\n\\n\ud83d\udc49 **Full source code:**  \\n[\ud83d\udd17 github.com/liviaerxin/mlops-fastapi-mlflow-minio](https://github.com/liviaerxin/mlops-fastapi-mlflow-minio)\\n\\n---\\n\x3c!--truncate--\x3e\\n\\n\u2e3b\\n\\n## Project Overview\\n\\nThis project provides:\\n\\n- A structured pipeline to **log, register, and serve ML models**\\n- Docker-based setup with **MLflow, FastAPI, and MinIO**\\n- Simple **training** and **inference** workflows\\n\\n\ud83d\udcc1 Project structure:\\n\\n```sh\\n.\\n\u251c\u2500\u2500 docker-compose.yml\\n\u251c\u2500\u2500 inference-server/\\n\u251c\u2500\u2500 mlflow-local-train-remote-register/\\n\u251c\u2500\u2500 mlflow-server/\\n\u251c\u2500\u2500 train.py\\n\u2514\u2500\u2500 README.md\\n```\\n\\n\ud83d\uddc2\ufe0f For full instructions, check the [README](https://github.com/liviaerxin/mlops-fastapi-mlflow-minio/README.md)\\n\\n## Key Components\\n\\n### MLflow\\n\\nMLflow is a platform to manage the ML lifecycle, including experimentation, reproducibility, and deployment.\\n\\n- Experiment tracking (`mlflow.log_param`, `mlflow.log_metric`)\\n- Model registration and versioning\\n- Stage promotion (`Staging`, `Production`)\\n\\n> NOTE: **MLflow** is used `remotely` in docker container environment here.\\n\\n### MinIO\\n\\nS3-compatible artifact store used by `MLflow` to save models. For production, you might migrate to use AWS S3 or GCS.\\n\\n> NOTE: **MinIO** is used `remotely` in docker container environment here.\\n\\n### FastAPI\\n\\nSimple REST API to serve ML models loaded from the MLflow registry.\\n\\nLoads the remote model via:\\n\\n```py\\nmlflow.set_tracking_uri(os.environ.get(\\"MLFLOW_SERVER\\", \\"http://127.0.0.1:5000\\"))\\nmodel = mlflow.pyfunc.load_model(f\\"models:/{MODEL_NAME}/{MODEL_STAGE}\\")\\n```\\n\\n> NOTE: **FastAPI** is used `remotely` in docker container environment here.\\n\\n### Training and Registering a Model\\n\\n> NOTE: **mlflow-local-train-remote-register** is used `locally` outside the docker container environment here.\\n\\nRun the training script:\\n\\n```sh\\npython train.py\\n```\\n\\nThen log and register it to a remote MLflow server:\\n\\n```sh\\npython register-remote.py\\n```\\n\\nKey code snippet:\\n\\n```sh\\nos.environ[\\"MLFLOW_S3_ENDPOINT_URL\\"] = \\"http://127.0.0.1:9000\\" # Expose the minio via host 9000 port\\nmlflow.set_tracking_uri(\\"http://127.0.0.1:5001\\") # Expose the mlflow server via host 5001 port\\nmi = mlflow.pytorch.log_model(model, artifact_path=\\"model\\", registered_model_name=MODEL_NAME)\\n```\\n\\n#### Bonus: Updating Models and Rolling Deployment\\n\\nYou can update models by:\\n\\n- Logging a new version to MLflow\\n- Promoting it to `Production` stage\\n- Using **FastAPI** logic to reload the latest version without downtime\\n\\nYou may also support blue-green deployments using Docker or Kubernetes.\\n\\n## Conclusion\\n\\nThis setup gives you a scalable and reproducible ML deployment pipeline with clear separation of concerns:\\n\\n- MLflow handles tracking and registry\\n- MinIO manages artifact storage\\n- FastAPI exposes inference endpoints\\n- Docker Compose glues it all together\\n\\n\u2e3b\\n\\n\ud83d\udd17 GitHub Repo\\n\\nAll code and instructions:\\n[\ud83d\udd17 github.com/liviaerxin/mlops-fastapi-mlflow-minio](https://github.com/liviaerxin/mlops-fastapi-mlflow-minio)"},{"id":"/celery-workflow","metadata":{"permalink":"/blog/celery-workflow","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/celery-workflow.mdx","source":"@site/../../blog/celery-workflow.mdx","title":"Orchestrating DAG-based task workflow in Celery","description":"Python Celery","date":"2025-04-20T00:00:00.000Z","tags":[{"inline":true,"label":"Python Celery","permalink":"/blog/tags/python-celery"}],"readingTime":0.86,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["Python Celery"],"description":"Python Celery","keywords":["Python Celery"],"image":"https://i.imgur.com/mErPwqL.png","date":"2025-04-20T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","permalink":"/blog/end-to-end-ml-deployment"},"nextItem":{"title":"Lightweight CI/CD with Git Hooks and Docker Compose","permalink":"/blog/ci-cd-githook-docker"}},"content":"What\'s **workflow** in Celery?\\n\\nIn **Celery**, **workflow** is composed of multiple **tasks**, and a **task** is deemed to be a universal unit of the **workflow**, as a function in the program. In **Celery**, it\'s recommended to divide a long-running task into multiple short-running tasks. **workflow** comes out to help ease the orchestrations of the work, such as `chain()` three tasks.\\n\\n[A demo workflow](https://github.com/liviaerxin/fastapi-celery-ml/blob/main/app/examples/celery_workflow.py)\\n\\n\x3c!--truncate--\x3e\\n\\n## Construct a workflow\\n\\n## Avoid running synchronous subtasks within a task\\n\\n## Asynchronous tasks with a task\\n\\n```py\\n@app.task(bind=True)\\ndef update_page_info(self, url):\\n    # fetch_page -> parse_page -> store_page\\n    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)\\n    # chain()\\n    self.replace(chain)\\n\\n@app.task()\\ndef fetch_page(url):\\n    return myhttplib.get(url)\\n\\n@app.task()\\ndef parse_page(page):\\n    return myparser.parse_document(page)\\n\\n@app.task(ignore_result=True)\\ndef store_page_info(info, url):\\n    PageInfo.objects.create(url=url, info=info)\\n```\\n\\n## Monitor the workflow\\n\\n\\n## Resources\\n\\n[Designing Dynamic Workflows with Celery and Python | by Marin Agli\u0107 | Data Engineer Things](https://blog.det.life/replacing-celery-tasks-inside-a-chain-b1328923fb02)\\n\\n[The Curious Case of Celery Work-flows](https://dev.to/akarshan/the-curious-case-of-celery-work-flows-39f7)\\n\\n[Celery ETA Tasks Demystified. At Instawork, we use Celery to queue\u2026 | by Oleg Pesok | Instawork Engineering](https://engineering.instawork.com/celery-eta-tasks-demystified-424b836e4e94)\\n\\n[Canvas: Designing Work-flows \u2014 Celery 5.3.6 documentation](https://docs.celeryq.dev/en/stable/userguide/canvas.html)"},{"id":"/ci-cd-githook-docker","metadata":{"permalink":"/blog/ci-cd-githook-docker","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/ci-cd-githook-docker.mdx","source":"@site/../../blog/ci-cd-githook-docker.mdx","title":"Lightweight CI/CD with Git Hooks and Docker Compose","description":"A lightweight CI/CD method using Git push and Docker, no third-party tools needed.","date":"2025-04-13T00:00:00.000Z","tags":[{"inline":true,"label":"ci/cd","permalink":"/blog/tags/ci-cd"},{"inline":true,"label":"docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"git","permalink":"/blog/tags/git"}],"readingTime":3.27,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"description":"A lightweight CI/CD method using Git push and Docker, no third-party tools needed.","keywords":["ci/cd","docker","git"],"image":"https://i.imgur.com/mErPwqL.png","tags":["ci/cd","docker","git"],"last_update":{"date":"2025-04-14T00:00:00.000Z"},"date":"2025-04-13T00:00:00.000Z","authors":["frank"]},"unlisted":false,"prevItem":{"title":"Orchestrating DAG-based task workflow in Celery","permalink":"/blog/celery-workflow"},"nextItem":{"title":"Intercepting HTTPs traffic from Android emulator","permalink":"/blog/how-to-intercept-https-traffic-from-android-emulator"}},"content":"For small projects or self-hosted apps, using a full-fledged CI/CD tool like GitHub Actions or Jenkins can be overkill. What if you could have automated deployments **without any third-party service**, and all you need is **Git and SSH**?\\n\\nIn this post, we\u2019ll walk through setting up a lightweight, no-cost CI/CD pipeline using **Git hooks** and **Docker Compose**, with deployments triggered by a simple `git push` to your production server.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Overview\\n\\nHere\u2019s the basic idea:\\n\\n1. You push your code from your dev machine to both:\\n   - A central Git host (like GitHub/GitLab)\\n   - Your production server (a bare Git repo)\\n2. The production server runs a `post-receive` hook to:\\n   - Checkout the latest code\\n   - Rebuild and restart Docker containers\\n\\nThis method is great for solo developers or small teams who want simple, fast deployments without external dependencies.\\n\\n---\\n\\n## Step-by-Step Setup\\n\\n### 1. Prepare the Production Server\\n\\n#### Install Git and Docker:\\n```bash\\nsudo apt update && sudo apt install git docker docker-compose -y\\n```\\n\\n#### Create a bare Git repository:\\n\\n```bash\\nmkdir -p ~/repos/myapp.git\\ncd ~/repos/myapp.git\\ngit init --bare\\n```\\n\\n#### Set up SSH access:\\n\\nFrom your dev machine, copy your SSH key to the production server:\\n```bash\\nssh-copy-id user@yourserver\\n```\\n\\nTest it:\\n```bash\\nssh user@yourserver\\n```\\n\\n---\\n\\n### 2. Add the Production Server as a Remote on Your Dev Machine\\n\\nIn your project repo:\\n```bash\\ngit remote add production ssh://user@yourserver/home/user/repos/myapp.git\\n```\\n\\nNow you can push to the production server:\\n```bash\\ngit push production main\\n```\\n\\n---\\n\\n### 3. Create a Post-Receive Hook on the Server\\n\\nOn the production server:\\n```bash\\nnano ~/repos/myapp.git/hooks/post-receive\\n```\\n\\nPaste the following:\\n```bash\\n#!/bin/bash\\nAPP_DIR=/var/www/myapp\\n\\n# Checkout code\\ngit --work-tree=$APP_DIR --git-dir=$(pwd) checkout -f\\n\\n# Deploy with Docker\\ncd $APP_DIR || exit\\ndocker compose down\\ndocker compose build\\ndocker compose up -d\\n```\\n\\nMake it executable:\\n```bash\\nchmod +x ~/repos/myapp.git/hooks/post-receive\\n```\\n\\n---\\n\\n## What Exactly Happens During `git push`\\n\\n1. You run:\\n   ```bash\\n   git push production main\\n   ```\\n\\n2. Your local Git client:\\n   - Connects to the production server over SSH.\\n   - Invokes `git-receive-pack` on the server\u2019s bare Git repo.\\n\\n3. Git negotiates what data is needed:\\n   - It sends new commits, trees, and blobs over SSH.\\n\\n4. The server\u2019s Git receives the data and updates the bare repo.\\n\\n5. The `post-receive` hook is automatically triggered:\\n   - It checks out the new code to the app directory.\\n   - It runs `docker compose` to deploy the latest version.\\n\\n6. Only once the hook script finishes does the `git push` complete on your dev machine.\\n\\nThis means your `git push` blocks and provides real-time feedback on deployment success or failure.\\n\\n---\\n\\n## How It Works\\n\\n- When you run `git push production main`, Git connects to the server over **SSH**.\\n- Your dev Git sends commit data to the **bare repo** on the server.\\n- Git automatically runs the `post-receive` hook.\\n- The hook checks out the new code and runs Docker commands.\\n\\nNo daemon, no polling, no fancy tools. Just Git + SSH + Docker.\\n\\n---\\n\\n## FAQ\\n\\n**Q: Does the push block until the deployment finishes?**\\n> Yes. The `git push` command will block until the `post-receive` hook finishes. That way, you get immediate feedback if the deployment fails.\\n\\n**Q: Does Git use SSH to send data?**\\n> Absolutely. All Git data (commits, trees, blobs) is transferred securely over SSH when using `ssh://` remotes.\\n\\n**Q: Can I still use GitHub/GitLab?**\\n> Yes! You can push to both:\\n```bash\\ngit push origin main      # Push to GitHub\\ngit push production main  # Deploy to server\\n```\\n\\n---\\n\\n## Final Thoughts\\n\\nThis setup gives you a super simple and secure way to deploy code with nothing more than Git and Docker. For many indie devs and internal tools, it\u2019s all you really need.\\n\\nWant logging? Add `>> /var/log/deploy.log 2>&1` to the hook.\\nWant async? Run the hook script in the background with `&`.\\n\\nHappy hacking! \ud83d\ude80"},{"id":"/how-to-intercept-https-traffic-from-android-emulator","metadata":{"permalink":"/blog/how-to-intercept-https-traffic-from-android-emulator","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-intercept-https-traffic-from-android-emulator.mdx","source":"@site/../../blog/how-to-intercept-https-traffic-from-android-emulator.mdx","title":"Intercepting HTTPs traffic from Android emulator","description":"How to intercept HTTPs traffic from Android Emulator","date":"2025-03-25T00:00:00.000Z","tags":[{"inline":true,"label":"how-to intercept","permalink":"/blog/tags/how-to-intercept"},{"inline":true,"label":"HTTPs","permalink":"/blog/tags/htt-ps"},{"inline":true,"label":"Android","permalink":"/blog/tags/android"}],"readingTime":1.36,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["how-to intercept","HTTPs","Android"],"description":"How to intercept HTTPs traffic from Android Emulator","keywords":["intercept HTTPs traffic","Android Emulator"],"image":"https://i.imgur.com/mErPwqL.png","date":"2025-03-25T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Lightweight CI/CD with Git Hooks and Docker Compose","permalink":"/blog/ci-cd-githook-docker"},"nextItem":{"title":"Generating self-signed SSL/TLS certificate for local IP address or local domain","permalink":"/blog/how-to-create-self-signed-certificate"}},"content":"Capturing HTTPS traffic from an Android device can be a crucial aspect of testing and debugging applications. Additionally, gaining insight into decrypted HTTPS messages can offer valuable information for troubleshooting or security analysis, albeit with ethical considerations in mind. Here, we explore two methods to achieve this: via an HTTPs proxy or a VPN.\\n\\n\x3c!-- truncate --\x3e\\n\\nMethods:\\n\\n- HTTPs Proxy:\\n    - Using an HTTPS proxy is a common approach to intercepting traffic from an Android device. This method involves setting up a proxy server that acts as an intermediary between the device and the internet, allowing for the capture and analysis of HTTPS requests and responses. \\n    - However, you have to install the Proxy SSL certificate on the Android device to facilitate decryption.\\n\\n- VPN Server:\\n    - Alternatively, leveraging a Virtual Private Network (VPN) can intercept HTTPS traffic from an Android device. By directing traffic through a VPN server, it becomes feasible to capture and analyze HTTPS requests and responses in transit.\\n\\nTools:\\n- MITM (Man In The Middle) Proxy: A versatile tool for intercepting and modifying HTTP and HTTPS traffic.\\n- Proxyman: A user-friendly proxy tool with advanced features tailored for macOS and iOS devices, but also compatible with Android via manual proxy setup.\\n- Fiddler Proxy: A robust proxy tool with powerful debugging capabilities, including support for decrypting HTTPS traffic.\\n- Charles Proxy: A popular proxy tool known for its comprehensive debugging features, including SSL proxying for inspecting encrypted traffic.\\n- HTTP Toolkit: A modern, cross-platform tool designed for intercepting, debugging, and mocking HTTP and HTTPS traffic.\\n\\n\x3c!--truncate--\x3e\\n\\n## Resources\\n\\nhttps://medium.com/hackernoon/intercept-https-traffic-on-a-android-emulator-46023f17f6b3\\n\\nhttps://httptoolkit.com/docs/guides/android/\\n\\nhttps://proxyman.io/posts/2020-09-19-Intercept-https-traffic-on-android-emulator\\n\\nhttps://kpj.github.io/misc/InterceptingHTTPTraffic.html\\n\\nhttps://www.reddit.com/r/androiddev/comments/17nfwyn/easiest_way_to_inspect_network_traffic_coming/\\n\\nhttps://docs.telerik.com/fiddler-everywhere/capture-traffic/capture-from-android\\n\\nhttps://www.linkedin.com/pulse/intercept-sslhttps-traffic-perform-penetration-testing-mayank-grover/\\n\\nhttps://www.reddit.com/r/androiddev/comments/14x8eed/way_or_viewing_network_requests/\\n\\nhttps://beguier.eu/nicolas/articles/android-mitm-intercept-trafic.html"},{"id":"/how-to-create-self-signed-certificate","metadata":{"permalink":"/blog/how-to-create-self-signed-certificate","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-create-self-signed-certificate.mdx","source":"@site/../../blog/how-to-create-self-signed-certificate.mdx","title":"Generating self-signed SSL/TLS certificate for local IP address or local domain","description":"Self Signed Certificate","date":"2025-02-04T00:00:00.000Z","tags":[{"inline":true,"label":"ssl","permalink":"/blog/tags/ssl"},{"inline":true,"label":"certificate","permalink":"/blog/tags/certificate"}],"readingTime":6.745,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["ssl","certificate"],"description":"Self Signed Certificate","keywords":["Self Signed Certificate"],"image":"https://i.imgur.com/mErPwqL.png","date":"2025-02-04T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Intercepting HTTPs traffic from Android emulator","permalink":"/blog/how-to-intercept-https-traffic-from-android-emulator"},"nextItem":{"title":"Mounting ISO image file on macOS and Linux","permalink":"/blog/how-to-mount-iso-file"}},"content":"In real life, when we build our website and make it public, some paid or free **Certificate Authority** (**CA**) will help us sign a certificate for our website **domain** (IP address is not acceptable!) and enable **SSL/TLS** connections from user browser to our server.\\n\\nGiven the secure reasons, the browser will only admit those servers\'s certificates signed from the authorized **CA**, and the **CA** certificate is kept in our host **system trust store**. In Linux, you can view the **CA** certificate file like `/etc/ssl/certs/ca-certificates.crt`.\\n\\n:::note\\nOne of the most popular Certificate Authorities is [Let\'s Encrypt](https://letsencrypt.org/), which is a free and non-profit CA.\\n:::\\n\\nHowever, in many internal networks and development environments, we often need **self-signed certificate** more frequently.\\n\\nHere is an example, we will generate a **local server certificate** that is signed by a **local CA**. Finally, let Chrome can visit our local website without security warning.\\n\\nIn brief, these steps we need to sign local sever certificate actually simulate how those CA sign certificates for public servers, as following:\\n\\n1. Create a local **Root CA**.\\n2. Create a **CSR**(Certificate Signing Request) file for local server `127.0.0.1`.\\n3. The local **Root CA** use the local server `127.0.0.1` **CSR** to generate a **certificate**.\\n4. Install the local **Root CA** into our system(Windows, Ubuntu or macOS) trust store.\\n5. Run a simple **https** server to test local server **certificate**.\\n\\nFor those official CA, they have to validate the domain is owned by the server before the `step 3`, and we can ignore `step 4` as they are already installed into the system or the browser trust store.\\n\\nAnd there is nice picture from [How to create your own self-signed root Certificate Authority(CA)](https://www.linkedin.com/pulse/how-create-your-own-self-signed-root-certificate-shankar-gomare/) to show the relationship between `CA`, `server` and `browser`.\\n\\n![](https://media.licdn.com/dms/image/C4E12AQGJ5hl3wTAyFg/article-inline_image-shrink_400_744/0/1589170084171?e=1701907200&v=beta&t=FaVSM-fIy4dc-SIftGYEuUc7GONcMLphssfteUKoWuA)\\n\\n\x3c!--truncate--\x3e\\n\\n\\n## 1. Create a local CA\\n\\nGenerate a file `RootCA.key` and a file `RootCA.crt` of our local root **CA**:\\n\\n```sh\\nopenssl req -x509 -nodes -new -sha256 -days 1024 -newkey rsa:2048 -keyout RootCA.key -out RootCA.crt -subj \\"/C=US/CN=Example-Root-CA\\"\\n```\\n\\nYou can change `Example-Root-CA` to others or add more fields to CA.\\n\\n[Optional] Create a CA with a configuration file,\\n\\n```sh\\nopenssl req -x509 -nodes -new -keyout RootCA.key -out RootCA.crt -config <(cat <<EOF\\n[ req ]\\ndefault_bits       = 2048\\ndefault_md         = sha256\\ndefault_days       = 3650\\nprompt             = no\\ndistinguished_name = req_distinguished_name\\n\\n[ req_distinguished_name ]\\nC  = US\\nST = California\\nL  = San Francisco\\nO  = Example Corp\\nOU = IT Department\\nCN = www.example.com\\nemailAddress = admin@example.com\\nEOF\\n)\\n```\\n\\n:::note\\n**process substitution** does not work in bash scripts!\\n:::\\n\\n\\n## 2. Create a signed certificate for the local server\\n\\nNext, we should apply the local **CA** to sign a **certificate** for our local server using the server\'s **Certificate Signing Request** (**CSR**)\\n, which will be accessed through the `localhost` or `127.0.0.1` from our local machine.\\n\\n### 2.1. Generate the server\'s CSR\\n\\nWhen generating the **CSR** file with OpenSSL, we can either specify certain details directly in the command line or use a configuration file. While you can provide some information via command-line arguments, complex configurations like specifying `[v3_req]` and `[alt_names]` in belowing are typically done through a configuration file.\\n\\n`subjectAltName` in `[v3_req]` will let you specify more than domain/IP addresses as **Subject Alternative Names** (**SANs**). And now modern browser require the server certificate to include **SANs**. Usage of the **Common Name** (**CN**) alone is not considered secure enough, and omitting **SANs** may result a certificate validation error!\\n\\nHere is an example for using pure arguments to specify `-subj`:\\n\\n```sh\\nopenssl req -new -newkey rsa:2048 -nodes -keyout privkey.pem -out csr.pem -subj \\"/C=US/ST=California/L=San Francisco/O=Example Corp/OU=IT Department/CN=www.example.com/emailAddress=admin@example.com\\"\\n```\\n\\nHere is an example to use the configuration file as `-config`.\\n\\n1. [Optional] Customize DNS by editing `/etc/hosts` (Other machines also have to do this if they would like to visit the server),\\n\\n```conf title=\\"/etc/hosts\\"\\n127.0.0.1   localhost\\n127.0.0.1   fake1.local\\n127.0.0.1   fake2.local\\n```\\n\\n2. Create a configure file for **CSR** including typical sections as:\\n\\n```conf title=\\"localhost.conf\\"\\n[req]\\ndefault_bits  = 2048\\ndistinguished_name = req_distinguished_name\\nreq_extensions = v3_req\\nprompt = no\\n\\n[req_distinguished_name]\\ncountryName = XX\\nstateOrProvinceName = N/A\\nlocalityName = N/A\\norganizationName = Self-signed certificate\\ncommonName = 127.0.0.1: Self-signed certificate\\n\\n[v3_req]\\nsubjectAltName = @alt_names\\n\\n[alt_names]\\nIP.1 = 127.0.0.1\\nDNS.1 = localhost\\nDNS.2 = fake1.local\\nDNS.3 = fake2.local\\n```\\n\\n3. Generates the **CSR**\\n\\nTo generate a **CSR** using the configuration file with OpenSSL, you can use the following command:\\n\\n```sh\\nopenssl req -new -nodes -keyout localhost.key -out localhost.csr -config localhost.conf\\n```\\n\\n[Optional] mix `-subj` and `-config`, to be short like:\\n\\n```sh\\nSAN_LIST=\\"[SAN]\\\\nsubjectAltName=DNS:localhost, DNS:*.localhost, IP:127.0.0.1\\"\\nopenssl req -new -nodes -newkey rsa:2048 -keyout localhost.key -out localhost.csr -subj \\"/C=US/ST=YourState/L=YourCity/O=Example CORP/CN=localhost.local\\" -reqexts SAN -config <(echo -e \\"$SAN_LIST\\")\\n```\\n\\nHere, `localhost.conf` is the configuration file and the two outputs are: \\n- `localhost.key` is the private key file for the local server to communicate with the clients securely.\\n- `localhost.csr` is the **CSR** file that the local server will use in the next step to sign its certificate from the local CA.\\n\\n\\n4. Verify the **CSR** file `localhost.csr`:\\n\\n```sh\\nopenssl req -text -noout -verify -in localhost.csr\\n```\\n\\n### 2.2. Sign the CSR with the local CA\\n\\nNow, it\'s time for **local CA** to sign a certificate for our local server by using the server\'s **CSR** `localhost.csr` file, thereby issuing a signed certificate.\\n\\n- Generates `localhost.crt` by using CSR `localhost.csr`,\\n\\n```sh\\nopenssl x509 -req -sha256 -days 1024 -in localhost.csr -CA RootCA.crt -CAkey RootCA.key -CAcreateserial -extensions v3_req -extfile localhost.conf -out localhost.crt\\n```\\n\\n:::info\\n`-extensions v3_req -extfile localhost.conf`: `openssl x509` will contain `subjectAltName` extension in the certificate.\\n:::\\n\\n:::warning\\nIf `X509` extensions(`subjectAltName`) are missing from the certificate, the browser will still report security issues, such as **its security certificate does not specify Subject Alternative Names.**\\n:::\\n\\nOr after **OpenSSL v3**, you can copy the extensions specified in the **CSR** to the certificate by `openssl x509` as this:\\n\\n```sh\\nopenssl x509 -req -sha256 -days 1024 -in localhost.csr -CA RootCA.crt -CAkey RootCA.key -CAcreateserial -copy_extensions copyall -out localhost.crt\\n```\\n\\n- View the generated `localhost.crt`:\\n\\n```sh\\nopenssl x509 -text -noout -in localhost.crt\\n```\\n\\n- Verify the generated`localhost.crt`:\\n\\n```sh\\nopenssl verify -verbose -CAfile RootCA.crt localhost.crt\\n```\\n\\n:::note\\nIf the CA and Subject are the same one, the step of creating the local CA can be skipped.\\n\\n```sh\\nopenssl req -x509 -nodes -days 730 -newkey rsa:2048 -keyout localhost.key -out localhost.crt -config localhost.conf\\n```\\n:::\\n\\n## 3. Use the signed certificate in the local server\\n\\nRun up a node https server to use the **signed certificate** for the local sever.\\n\\n```sh\\nnpx http-server -p 8082 --ssl --cert localhost.crt --key localhost.key\\n```\\n\\nThen visit:\\n\\n- https://127.0.0.1:8082/\\n- https://localhost:8082/\\n\\nThe browser will give you security warning as the local **root CA** is not trusted in default.\\n\\n## 4. Install the local CA\\n\\nTO trust the root **local CA**, we must install the **local CA** certificate `RootCA.crt` into each system **trust store** or each browser.\\n\\n- Windows system trust store\\n- Ubuntu system trust store\\n- macOS system trust store\\n\\nThen visit again, the browser will show green!\\n\\n## [Optional] Sign the CSR with `openssl ca`\\n\\nFor complicated configuration for CA to sign a certificate, you can use `openssl ca` and the configuration file is like:\\n\\n```sh\\ncd /path/to/your/ca/\\nmkdir -p newcerts\\ntouch index.txt\\necho 1000 > serial\\n```\\n\\n```sh\\ncat <<EOF > /path/to/your/ca/openssl.cnf\\n[ ca ]\\ndefault_ca = CA_default\\n\\n[ CA_default ]\\ndir               = /path/to/your/ca\\ndatabase          = $dir/index.txt\\nnew_certs_dir     = $dir/newcerts\\ncertificate       = $dir/RootCA.crt\\nserial            = $dir/serial\\nprivate_key       = $dir/RootCA.key\\ndefault_days      = 365\\ndefault_md        = sha256\\npolicy            = policy_any\\nx509_extensions   = usr_cert\\ncopy_extensions   = copy\\n\\n[ policy_any ]\\ncountryName             = supplied\\nstateOrProvinceName     = supplied\\norganizationName        = supplied\\norganizationalUnitName  = optional\\ncommonName              = supplied\\nemailAddress            = optional\\n\\n[ usr_cert ]\\nbasicConstraints=CA:FALSE\\nnsCertType = client, email\\nnsComment = \\"OpenSSL Generated Certificate\\"\\nsubjectKeyIdentifier=hash\\nauthorityKeyIdentifier=keyid,issuer\\nEOF\\n```\\n\\n```sh\\nopenssl ca -config /path/to/your/ca/openssl.cnf -in localhost.csr -out localhost.crt -batch\\n```\\n\\n## Troubleshooting\\n\\n### Chrome **red** security warning\\n\\n1. Go to `Developer Tools`.\\n2. Click `Security` tab.\\n3. Check `Security overview` issues.\\n\\n## Resources\\n\\n[How to create an HTTPS certificate for localhost domains \xb7 GitHub](https://gist.github.com/cecilemuller/9492b848eb8fe46d462abeb26656c4f8)\\n\\n[How to add X.509 extensions to certificate OpenSSL | GoLinuxCloud](https://www.golinuxcloud.com/add-x509-extensions-to-certificate-openssl/)\\n\\n[GitHub - FiloSottile/mkcert: A simple zero-config tool to make locally trusted development certificates with any names you\'d like.](https://github.com/FiloSottile/mkcert)"},{"id":"/how-to-mount-iso-file","metadata":{"permalink":"/blog/how-to-mount-iso-file","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-mount-iso-file.mdx","source":"@site/../../blog/how-to-mount-iso-file.mdx","title":"Mounting ISO image file on macOS and Linux","description":"How to mount ISO file","date":"2024-12-21T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"},{"inline":true,"label":"osx","permalink":"/blog/tags/osx"},{"inline":true,"label":"linux","permalink":"/blog/tags/linux"}],"readingTime":1.61,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["how-to","osx","linux"],"description":"How to mount ISO file","keywords":["How to mount ISO file"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-12-21T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Generating self-signed SSL/TLS certificate for local IP address or local domain","permalink":"/blog/how-to-create-self-signed-certificate"},"nextItem":{"title":"Inspect Shared Library","permalink":"/blog/inspect-shared-library"}},"content":"For viewing the content of the **ISO** image file like `*.iso`, we can mount it to filesystem and loop up its contained files.\\n\\nMounting the **ISO** image file in linux is much easier than doing in macOS. Because **ISO** use `ISO9660` file system while the `hdiutil` in macOS does not support it originally. That will require more steps to implement in comparison with one command like `mount ` in Linux.\\n\\n[How to mount iso image in Linux](https://www.cyberciti.biz/tips/how-to-mount-iso-image-under-linux.html)\\n\\n[osx - Can a Mac mount a Debian install CD? - Unix & Linux Stack Exchange](https://unix.stackexchange.com/questions/298685/can-a-mac-mount-a-debian-install-cd)\\n\\n\x3c!--truncate--\x3e\\n\\n## Mount ISO file on Linux\\n\\n\\n## Mount ISO file on macOS\\n\\n1. Attaching as a block device\\n\\n```sh\\n# the \'-nomount\' option avoids the \'mount failed\' error\\n\u276f hdiutil attach -nomount mantic-mini-iso-amd64.iso\\n/dev/disk6          \\tGUID_partition_scheme          \\t\\n/dev/disk6s1        \\tMicrosoft Basic Data           \\t\\n/dev/disk6s2        \\tEFI                            \\t\\n/dev/disk6s3        \\tMicrosoft Basic Data  \\n```\\n\\n```sh\\n\u276f diskutil info /dev/disk6s2\\n   Device Identifier:         disk6s2\\n   Device Node:               /dev/disk6s2\\n   Whole:                     No\\n   Part of Whole:             disk6\\n\\n   Volume Name:               ESP\\n   Mounted:                   No\\n\\n   Partition Type:            EFI\\n   File System Personality:   MS-DOS FAT12\\n   Type (Bundle):             msdos\\n   Name (User Visible):       MS-DOS (FAT12)\\n```\\n\\n2. [Optional] Load CD9660\\n\\n```sh\\n# Load the kext module\\n\u276f sudo kmutil load -p /System/Library/Extensions/cd9660.kext\\n```\\n\\n3. Mount the disk with cd9660 (aka ISO9660) file system\\n\\n```sh\\n# create mount point\\n\u276f mkdir -p /tmp/ubuntu-mantic-iso\\n\\n# mount the disk\\n\u276f mount -t cd9660 /dev/disk6 /tmp/ubuntu-mantic-iso\\n```\\n\\nView the `iso` files,\\n\\n```sh\\n\u276f tree -h -L 3 /tmp/ubuntu-mantic-iso\\n[2.0K]  /tmp/ubuntu-mantic-iso\\n\u251c\u2500\u2500 [2.0K]  EFI\\n\u2502\xa0\xa0 \u2514\u2500\u2500 [2.0K]  boot\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [938K]  bootx64.efi\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [2.2M]  grubx64.efi\\n\u2502\xa0\xa0     \u2514\u2500\u2500 [841K]  mmx64.efi\\n\u251c\u2500\u2500 [2.0K]  boot\\n\u2502\xa0\xa0 \u2514\u2500\u2500 [2.0K]  grub\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [2.0K]  fonts\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [ 169]  grub.cfg\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [ 38K]  i386-pc\\n\u2502\xa0\xa0     \u2514\u2500\u2500 [ 36K]  x86_64-efi\\n\u251c\u2500\u2500 [2.0K]  boot.catalog\\n\u2514\u2500\u2500 [2.0K]  casper\\n    \u251c\u2500\u2500 [ 56M]  initrd\\n    \u2514\u2500\u2500 [ 13M]  vmlinuz\\n\\n9 directories, 7 files\\n```\\n\\n4. Umount the disk\\n\\n```sh\\n\u276f umount /dev/disk6\\n```\\n\\n5. Detach the disk\\n\\n```sh\\n\u276f hdiutil detach /dev/disk6\\n```"},{"id":"/inspect-shared-library","metadata":{"permalink":"/blog/inspect-shared-library","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/inspect-shared-library.md","source":"@site/../../blog/inspect-shared-library.md","title":"Inspect Shared Library","description":"Test Dynamic Library","date":"2024-12-02T00:00:00.000Z","tags":[{"inline":true,"label":"debug","permalink":"/blog/tags/debug"},{"inline":true,"label":"shared library","permalink":"/blog/tags/shared-library"},{"inline":true,"label":"osx","permalink":"/blog/tags/osx"},{"inline":true,"label":"windows","permalink":"/blog/tags/windows"},{"inline":true,"label":"linux","permalink":"/blog/tags/linux"}],"readingTime":1.97,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/test-dynamic-library.md"},"authors":["frank"],"description":"Test Dynamic Library","keywords":["debug","dynamic library","shared library"],"image":"https://i.imgur.com/mErPwqL.png","tags":["debug","shared library","osx","windows","linux"],"date":"2024-12-02T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Mounting ISO image file on macOS and Linux","permalink":"/blog/how-to-mount-iso-file"},"nextItem":{"title":"QEMU Direct Linux Kernel Boot","permalink":"/blog/qemu-linux-kernel-boot"}},"content":"Concepts:\\n\\n- Show shared libraries dependencies(detect what shared libraries an executable or a another shared libraries depend on)\\n- Check/Test dependent shared libraries loaded successfully\\n\\n\x3c!-- truncate --\x3e\\n\\n## Using `ldd` Command\\n\\nAvailable in Linux:\\n\\n```sh\\nldd /usr/bin/vim\\n\\tlinux-vdso.so.1 (0x00007ffc75fb1000)\\n\\tlibgtk-3.so.0 => /usr/lib/libgtk-3.so.0 (0x00007fa4dcb5e000)\\n\\tlibgdk-3.so.0 => /usr/lib/libgdk-3.so.0 (0x00007fa4dca64000)\\t\\n\\tlibXau.so.6 => /usr/lib/libXau.so.6 (0x00007fa4db7a9000)\\n        ....\\n\\tliblzma.so.5 => /usr/lib/liblzma.so.5 (0x00007fa4db63f000)\\n\\tliblz4.so.1 => /usr/lib/liblz4.so.1 (0x00007fa4db61d000)\\n\\tlibgcrypt.so.20 => /usr/lib/libgcrypt.so.20 (0x00007fa4db4ff000)\\n\\tlibgpg-error.so.0 => /usr/lib/libgpg-error.so.0 (0x00007fa4db4d8000)\\n```\\n\\n## Using `objdump` Command\\n\\nAvailable in Linux:\\n\\n```sh\\nobjdump -p /usr/bin/vim | grep \'NEEDED\'\\n  NEEDED               libpython3.7m.so.1.0\\n  NEEDED               libcrypt.so.2\\n  NEEDED               libpthread.so.0\\n  NEEDED               libdl.so.2\\n  NEEDED               libutil.so.1\\n  NEEDED               libm.so.6\\n  NEEDED               libselinux.so.1\\n  NEEDED               libtinfo.so.6\\n  NEEDED               libacl.so.1\\n  NEEDED               libgpm.so.2\\n  NEEDED               libc.so.6\\n```\\n\\n## Using `readelf` Command\\n\\nAvailable in Linux:\\n\\n```sh\\nreadelf --dynamic /usr/bin/vim | grep NEEDED\\n 0x0000000000000001 (NEEDED)             Shared library: [libpython3.7m.so.1.0]\\n 0x0000000000000001 (NEEDED)             Shared library: [libcrypt.so.2]\\n 0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]\\n 0x0000000000000001 (NEEDED)             Shared library: [libdl.so.2]\\n 0x0000000000000001 (NEEDED)             Shared library: [libutil.so.1]\\n 0x0000000000000001 (NEEDED)             Shared library: [libm.so.6]\\n 0x0000000000000001 (NEEDED)             Shared library: [libselinux.so.1]\\n 0x0000000000000001 (NEEDED)             Shared library: [libtinfo.so.6]\\n 0x0000000000000001 (NEEDED)             Shared library: [libacl.so.1]\\n 0x0000000000000001 (NEEDED)             Shared library: [libgpm.so.2]\\n 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]\\n```\\n\\n## Using `otool` Command\\n\\nAvailable in OSX:\\n\\n```sh\\notool -L libOpenCvSharpExtern.dylib\\n```\\n\\n## Reading the `/proc/<pid>/maps` File\\n\\nAvailable in Linux:\\n\\n```sh\\ncat /proc/179015/maps \\n...\\n7f2cb67c3000-7f2cb67c6000 r--p 00000000 08:13 3810274                    /usr/lib/libnss_files-2.31.so\\n7f2cb67c6000-7f2cb67cd000 r-xp 00003000 08:13 3810274                    /usr/lib/libnss_files-2.31.so\\n..\\n7f2cb6a89000-7f2cb6a8a000 r--p 00002000 08:13 3810903                    /usr/lib/libutil-2.31.so\\n7f2cb6a8a000-7f2cb6a8b000 r--p 00002000 08:13 3810903                    /usr/lib/libutil-2.31.so\\n...\\n7f2cb9802000-7f2cb9803000 rw-p 00000000 00:00 0 \\n7ffe77658000-7ffe7767a000 rw-p 00000000 00:00 0                          [stack]\\n7ffe776c8000-7ffe776cc000 r--p 00000000 00:00 0                          [vvar]\\n7ffe776cc000-7ffe776ce000 r-xp 00000000 00:00 0                          [vdso]\\nffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0                  [vsyscall]\\n```\\n\\n```sh\\nawk \'$NF!~/\\\\.so/{next} {$0=$NF} !a[$0]++\' /proc/179015/maps\\n...\\n/usr/lib/libpython3.8.so.1.0\\n/usr/lib/libgpg-error.so.0.29.0\\n/usr/lib/libgcrypt.so.20.2.5\\n/usr/lib/liblz4.so.1.9.2\\n/usr/lib/liblzma.so.5.2.5\\n/usr/lib/libsystemd.so.0.28.0\\n/usr/lib/libogg.so.0.8.4\\n/usr/lib/libvorbis.so.0.4.8\\n/usr/lib/libblkid.so.1.1.0\\n/usr/lib/libXdmcp.so.6.0.0\\n/usr/lib/libXau.so.6.0.0\\n/usr/lib/libdatrie.so.1.3.5\\n...\\n```\\n\\n## Using `vmmap` Command\\n\\n## Using `ctypes` in Python\\n\\n```py\\nimport ctypes\\nctypes.cdll.LoadLibrary(\\"libOpenCvSharpExtern.so\\")\\nctypes.CDLL(\\"libOpenCvSharpExtern.so\\")\\n```\\n\\n```c\\ndlopen()\\nDYLD_PRINT_LIBRARIES=1 dlopen_test.out /opt/vcpkg/installed/arm64-osx-dynamic/lib/libpng16.dylib\\n```\\n\\n```sh\\nobjdump -p /usr/local/lib/libOpenCvSharpExtern.so\\n```\\n\\n### Using `nm`\\n\\nShow list of symbols:\\n\\n```sh\\n\u276f nm -g /opt/vcpkg/installed/arm64-osx-dynamic/lib/libintl.8.dylib\\n                 U _CFArrayGetCount\\n                 U _CFArrayGetValueAtIndex\\n                 U _CFGetTypeID\\n                 U _CFLocaleCopyPreferredLanguages\\n                 U _CFPreferencesCopyAppValue\\n                 U _CFRelease\\n                 U _CFStringGetCString\\n                 U _CFStringGetTypeID\\n                 U __DefaultRuneLocale\\n                 U ___CFConstantStringClassReference\\n```\\n\\n### Using `dumpbin`\\n\\nAvailable in Windows\\n\\nShow dependent dynamic libraries(`DLL`):\\n\\n```powershell\\ndumpbin /dependents your_dll_file.dll\\n```\\n\\n### Using `Microsoft.PowerShell`\\n\\n```powershell\\n(Get-Command \\"C:\\\\Path\\\\To\\\\Thing.dll\\").FileVersionInfo\\n(Get-Item \\"C:\\\\Windows\\\\System32\\\\nvcuda.dll\\").VersionInfo\\n```\\n\\n## Useful Environment Variables\\n\\nOSX:\\n\\n- `DYLD_LIBRARY_PATH`\\n- `DYLD_PRINT_LIBRARIES`\\n- `DYLD_PRINT_STATISTICS`\\n\\nLinux:\\n\\n- `LD_LIBRARY_PATH`\\n- `LD_DEBUG=libs`\\n\\n## References\\n\\n[Additional MSVC Build Tools](https://learn.microsoft.com/en-us/cpp/build/reference/c-cpp-build-tools)\\n\\n[How to Show All Shared Libraries Used by Executables in Linux](https://www.baeldung.com/linux/show-shared-libraries-executables)"},{"id":"/qemu-linux-kernel-boot","metadata":{"permalink":"/blog/qemu-linux-kernel-boot","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/qemu-linux-kernel-boot.mdx","source":"@site/../../blog/qemu-linux-kernel-boot.mdx","title":"QEMU Direct Linux Kernel Boot","description":"QEMU Linux Kernel Boot","date":"2024-09-26T00:00:00.000Z","tags":[{"inline":true,"label":"qemu","permalink":"/blog/tags/qemu"},{"inline":true,"label":"kernel","permalink":"/blog/tags/kernel"},{"inline":true,"label":"initramfs","permalink":"/blog/tags/initramfs"}],"readingTime":2.735,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["qemu","kernel","initramfs"],"description":"QEMU Linux Kernel Boot","keywords":["QEMU Linux Kernel Boot"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-09-26T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Inspect Shared Library","permalink":"/blog/inspect-shared-library"},"nextItem":{"title":"QEMU Emulate Raspberry Pi 3 and 4","permalink":"/blog/qemu-raspberry-pi"}},"content":"Here, I will employ QEMU to emulate a minimal **Linux x86_64** platform with a minimal root filesystem from scratch, as well as debugging with `GDB`:\\n\\n- Build **Linux x86_64** kernel\\n- Build **Linux x86_64** rootfs(root filesystem)\\n- Run QEMU\\n- Debug with `GDB`\\n\\nWhy do I use QEMU to boot Linux kernel directly with skipping BIOS/UEFI boot procedures?\\n\\nUse QEMU to launch a Linux kernel directly without having to make a fully bootable disk image. This is very useful for:\\n\\n- Linux kernel testing\\n- root filesystem testing\\n- arm system emulation\\n\\n\x3c!--truncate--\x3e\\n\\n## Prerequisites\\n\\nOn Ubuntu,\\n\\n```sh\\nsudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison\\n```\\n\\nOn macOS, you need create a **Case Sensitive** filesystem and use **GNU GCC** instead of `Clang` the following ways:\\n\\n```sh\\nhdiutil create -size 20g -type SPARSE -fs \\"Case-sensitive HFS+\\" -volname brosx brosx.sparseimage\\nhdiutil attach brosx.sparseimage\\n```\\n\\n```sh\\nhdiutil detach /Volumes/brosx -force\\n```\\n\\n```sh\\nbrew install gpatch gcc flock attr libtool libart\\n```\\n\\n```sh\\nln -s /opt/homebrew/bin/gcc-13 /opt/homebrew/bin/gcc\\nn -s /opt/homebrew/bin/gcc-13 /opt/homebrew/bin/cc\\nln -s /opt/homebrew/bin/g++-13 /opt/homebrew/bin/g++\\nln -s /opt/homebrew/bin/g++-13 /opt/homebrew/bin/c++\\n```\\n\\n```sh\\nrm /opt/homebrew/bin/gcc /opt/homebrew/bin/cc /opt/homebrew/bin/g++ /opt/homebrew/bin/c++\\n```\\n\\n## Build Linux kernel\\n\\n```sh\\nwget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.1.55.tar.xz\\n```\\n\\n\\n```sh\\ntar xvf linux-6.1.55.tar.xz\\ncd linux-6.1.55\\n```\\n\\n```sh\\n# Use the default `x86_64` configuration file form `/x86/configs/x86_64_defconfig`\\nmake ARCH=x86_64 x86_64_defconfig \\n```\\n\\n```sh\\n# Tweak some options for GDB and initramfs\\nmake menuconfig\\n```\\n\\n```sh\\nmake -j8\\n```\\n\\nGenerate kernel file `./arch/x86/boot/bzImage`.\\n\\n:::note\\nTo extract `vmlinux` from `bzImage`,\\n\\n```sh\\n./scripts/extract-vmlinux ./arch/x86_64/boot/bzImage >./arch/x86_64/boot/vmlinux\\n```\\n\\n:::\\n\\n## Build root filesystem\\n\\n```sh\\ngit clone https://github.com/buildroot/buildroot.git\\ncd buildroot\\n```\\n\\n```sh\\nmake menuconfig\\n```\\n\\nChoose `x86_64` as Target Architecture and `ext4` root file system.\\n\\n```sh\\nmake -j8\\n```\\n\\nGenerate root filesystem disk `./output/images/rootfs.ext4`.\\n\\n## Run QEMU\\n\\nCopy `bzImage` and `rootfs.ext4` to any host machine with QEMU available.\\n\\n```sh\\nrsync -l ./linux-6.1.55/arch/x86/boot/bzImage destination_directory/\\nrsync -l ./buildroot/output/images/rootfs.ext4 destination_directory/\\n```\\n\\n```sh\\nkernel=\\"$PWD/linux_qemu/x86_64/bzImage\\"\\nvmlinuz=\\"$PWD/linux_qemu/x86_64/vmlinux\\"\\ninitrd=\\"$PWD/linux_qemu/x86_64/rootfs.ext4\\"\\nimg=\\"$PWD/linux_qemu/x86_64/rootfs.ext4\\"\\n```\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/zero console=ttyS0\\"\\n```\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -hda $img \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda rootfstype=ext4 console=ttyS0\\" \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nDefault password: `root`\\n\\n## Debug Linux kernel\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -s -S \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/zero console=ttyS0 nokaslr\\"\\n```\\n\\nOptions in details,\\n\\n- `-s`: allows port `tcp::1234` for remote debug\\n- `-S`: stop CPU until continue from GDB what is connected to tcp `1234` port\\n- `-append`\\n  - `nokaslr`: turn off **KASLR**\\n\\nOr with root filesystem,\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -s -S \\\\\\n    -kernel $kernel \\\\\\n    -hda $img \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda rootfstype=ext4 console=ttyS0 nokaslr\\" \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nEnter `gdb`,\\n\\n```sh\\n$ gdb ./vmlinux\\n```\\n\\nIn `gdb` shell,\\n\\n```sh\\n(gdb) target remote 10.6.64.243:1234\\nRemote debugging using 10.6.64.243:1234\\nwarning: No executable has been specified and target does not support\\ndetermining executable automatically.  Try using the \\"file\\" command.\\n0x000000000000fff0 in ?? ()\\n(gdb) continue\\nContinuing.\\n```\\n\\n## Resources\\n\\n[Daniel P. Berrang\xe9  \xbb Blog Archive   \xbb make-tiny-image.py: creating tiny initrds for testing QEMU or Linux kernel/userspace behaviour](https://www.berrange.com/posts/2023/03/09/make-tiny-image-py-creating-tiny-initrds-for-testing-qemu-or-linux-kernel-userspace-behaviour/)\\n\\n[GitHub - dhruvvyas90/qemu-rpi-kernel: Qemu kernel for emulating Rpi on QEMU](https://github.com/dhruvvyas90/qemu-rpi-kernel)\\nhttps://medicineyeh.wordpress.com/2016/03/29/buildup-your-arm-image-for-qemu/\\n\\n[Prepare the environment for developing Linux kernel with qemu. | by DaeSeok Youn | Medium](https://medium.com/@daeseok.youn/prepare-the-environment-for-developing-linux-kernel-with-qemu-c55e37ba8ade)\\n\\n[](https://bootlin.com/pub/conferences/2013/kernel-recipes/rootfs-kernel-developer/rootfs-kernel-developer.pdf)"},{"id":"/qemu-raspberry-pi","metadata":{"permalink":"/blog/qemu-raspberry-pi","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/qemu-raspberry-pi.mdx","source":"@site/../../blog/qemu-raspberry-pi.mdx","title":"QEMU Emulate Raspberry Pi 3 and 4","description":"QEMU emulate Raspberry Pi 3/4","date":"2024-09-23T00:00:00.000Z","tags":[{"inline":true,"label":"qemu","permalink":"/blog/tags/qemu"},{"inline":true,"label":"raspberry-pi","permalink":"/blog/tags/raspberry-pi"},{"inline":true,"label":"osx","permalink":"/blog/tags/osx"}],"readingTime":8.345,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["qemu","raspberry-pi","osx"],"description":"QEMU emulate Raspberry Pi 3/4","keywords":["QEMU Raspberry Pi 3/4"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-09-23T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"QEMU Direct Linux Kernel Boot","permalink":"/blog/qemu-linux-kernel-boot"},"nextItem":{"title":"Exploring cross compilation: ARM on x86_64","permalink":"/blog/how-to-cross-compilation"}},"content":"In this blog, **QEMU** is employed to emulate **Raspberry Pi 3/4** in **mac M1** host(it\'s also supposed to work in **Windows/Linux** with a little tweak). I will demonstrate **two** different ways to emulate **Raspberry Pi 3** and **Raspberry Pi 4** in respect. These two ways are different by using different **QEMU machines** as you would like to use:\\n\\n1. `-machine raspi3b`: raspberry pi 3b machine to emulate **Raspberry Pi 3**.\\n2. `-machine virt`: general arm machine to emulate **Raspberry Pi 4**.\\n\\n:::note\\nIn mac M1 with setting `-machine virt`, I use the hardware acceleration by `-accel hvf`. In Windows(x86_64), the hardware acceleration for `aarch64` is not available, so removing the hardware acceleration will work as well in Windows.\\n:::\\n\\nFor both of these two, we still need prepare some common steps before running **QEMU**:\\n\\n- Extract the appropriate kernel, device tree or root filesystem\\n\\n\x3c!--truncate--\x3e\\n\\nThis blog will emulate Raspberry Pi using QEMU in mac M1 host using the new image `2024-05-03-raspios-bullseye-arm64-lite.img`.\\n\\nThe default `user:pi` and `password:raspberry` have been removed from this image. In order to log in, we have to write `user` and `password` to the image before booting. These steps can be skipped when booting previous images.\\n\\n## Prerequisites\\n\\n- **Docker**\\n  - be required in macOS\\n  - can be skipped in Linux\\n  - can use `wsl` as an alternative in Windows\\n- **QEMU**\\n  - `homebrew` install in macOS\\n- **Raspberry Pi image**: `2024-05-03-raspios-bullseye-arm64-lite.img`\\n\\nSince I am in mac M1, and the `raspberry pi` image which contains a `fat` filesystem as boot and a `ext4` filesystem as OS, we need write some configuration into it. So I will use a **Docker Ubuntu** container to do the operation on the the filesystem. There some other tools to do the like of these operations:\\n\\n- `ext4fuse` is free and easy to install via `homebrew`, but it has limit as read-only access.\\n- `ExtFS` from `Paragon` supports read-write access while you need pay for it.\\n- `virtual machine`\\n  - `Docker` in OSX make use of `virtual machine` while it is quick and flexible to use.\\n\\n## Raspberry Pi image\\n\\n```sh\\ncd ~\\nwget https://downloads.raspberrypi.org/raspios_arm64/images/raspios_arm64-2024-05-03/2024-05-03-raspios-bullseye-arm64-lite.img.xz\\nxz -d 2024-05-03-raspios-bullseye-arm64-lite.img.xz\\n```\\n\\n## Docker Ubuntu container\\n\\nMount the **folder** including `2024-05-03-raspios-bullseye-arm64-lite.img`\\n\\n```sh\\ndocker run -it -d --privileged -v $PWD:/qemu --name ubuntu ubuntu\\ndocekr exec -it ubuntu bash\\n```\\n\\n## Extracting Kernel and device tree\\n\\nOperations all in Ubuntu container.\\n\\n```sh\\nroot@f36a3251391d:/qemu# fdisk -l 2024-05-03-raspios-bullseye-arm64-lite.img \\nDisk 2024-05-03-raspios-bullseye-arm64-lite.img: 1.96 GiB, 2101346304 bytes, 4104192 sectors\\nUnits: sectors of 1 * 512 = 512 bytes\\nSector size (logical/physical): 512 bytes / 512 bytes\\nI/O size (minimum/optimal): 512 bytes / 512 bytes\\nDisklabel type: dos\\nDisk identifier: 0x544c6228\\n\\nDevice                                      Boot  Start     End Sectors  Size Id Type\\n2024-05-03-raspios-bullseye-arm64-lite.img1        8192  532479  524288  256M  c W95 FAT32 (LBA)\\n2024-05-03-raspios-bullseye-arm64-lite.img2      532480 4104191 3571712  1.7G 83 Linux\\n```\\n\\n- The first partition is boot filesystem.\\n- The second partition is real root filesystem.\\n\\nAll the data we need is in the first partition, to do the operation is mounting it.\\n\\nThe offset of the first partition: 8192 * 512 = 4194304,\\n\\n```sh\\nroot@f36a3251391d:/qemu# mount -o loop,offset=4194304 2024-05-03-raspios-bullseye-arm64-lite.img /mnt/rpi-boot/\\n```\\n\\n\\n```sh\\nroot@f36a3251391d:/qemu# ls -ls /mnt/rpi-boot/\\ntotal 30244\\n  20 -rwxr-xr-x 1 root root   18693 Apr  5 11:32 COPYING.linux\\n   2 -rwxr-xr-x 1 root root    1594 Apr  5 11:32 LICENCE.broadcom\\n  30 -rwxr-xr-x 1 root root   30390 Apr  5 11:32 bcm2710-rpi-2-b.dtb\\n  32 -rwxr-xr-x 1 root root   32753 Apr  5 11:32 bcm2710-rpi-3-b-plus.dtb\\n  32 -rwxr-xr-x 1 root root   32142 Apr  5 11:32 bcm2710-rpi-3-b.dtb\\n  30 -rwxr-xr-x 1 root root   30285 Apr  5 11:32 bcm2710-rpi-cm3.dtb\\n  32 -rwxr-xr-x 1 root root   31318 Apr  5 11:32 bcm2710-rpi-zero-2-w.dtb\\n  32 -rwxr-xr-x 1 root root   31318 Apr  5 11:32 bcm2710-rpi-zero-2.dtb\\n  52 -rwxr-xr-x 1 root root   52593 Apr  5 11:32 bcm2711-rpi-4-b.dtb\\n  52 -rwxr-xr-x 1 root root   52682 Apr  5 11:32 bcm2711-rpi-400.dtb\\n  38 -rwxr-xr-x 1 root root   38182 Apr  5 11:32 bcm2711-rpi-cm4-io.dtb\\n  52 -rwxr-xr-x 1 root root   53202 Apr  5 11:32 bcm2711-rpi-cm4.dtb\\n  50 -rwxr-xr-x 1 root root   50504 Apr  5 11:32 bcm2711-rpi-cm4s.dtb\\n  52 -rwxr-xr-x 1 root root   52476 Apr  5 11:32 bootcode.bin\\n   2 -rwxr-xr-x 1 root root     154 May  3 03:11 cmdline.txt\\n   4 -rwxr-xr-x 1 root root    2109 May  3 02:53 config.txt\\n  ...\\n   2 -rwxr-xr-x 1 root root     145 May  3 03:11 issue.txt\\n8028 -rwxr-xr-x 1 root root 8219600 Apr  5 11:32 kernel8.img\\n  ...\\n```\\n\\n\\nTo run QEMU we will need the **kernel** and **device tree**, so let\u2019s copy them out:\\n\\n```sh\\nroot@f36a3251391d:/qemu# cp /mnt/rpi-boot/kernel8.img .\\nroot@f36a3251391d:/qemu# cp /mnt/rpi-boot/bcm2710-rpi-3-b.dtb .\\n```\\n\\n## Setting up default user\\n\\nOperations all in docker container.\\n\\nNow in order to set up user and enable ssh in default, we need write files into `/userconf` and `/ssh` under the boot filesystem mounted as `/mnt/rpi-boot/`.\\n\\nSet up a default `user:pi` and `password:raspberry`.\\n\\nHash password `raspberry` using `openssl`,\\n\\n```sh\\nroot@f36a3251391d:/qemu# openssl passwd\\nPassword: \\nVerifying - Password: \\n$1$d...AvcL$wqfUqTIauUP1TVJ/uU1td0\\n```\\n\\n```sh\\nroot@f36a3251391d:/qemu# echo \'pi:$1$d...AvcL$wqfUqTIauUP1TVJ/uU1td0\' | tee /mnt/rpi-boot/userconf\\n```\\n\\nEnable `ssh`,\\n\\n```sh\\nroot@f36a3251391d:/qemu# touch /mnt/rpi-boot/ssh\\n```\\n\\n```sh\\nroot@f36a3251391d:/qemu# umount /mnt/rpi-boot\\n```\\n\\n## Running QEMU\\n\\n### Emulate Raspberry Pi 3\\n\\nNow switch back to the host macOS to run `QEMU`,\\n\\nResize the image to the next power of 2 size,\\n\\nThe original size,\\n\\n```sh\\n\u276f stat -f%z 2024-05-03-raspios-bullseye-arm64-lite.img\\n2101346304\\n```\\n\\nTo resize to `4GB`,\\n\\n```sh\\nqemu-img resize ./2024-05-03-raspios-bullseye-arm64-lite.img 4G\\n```\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine raspi3b \\\\\\n    -cpu cortex-a72 \\\\\\n    -nographic \\\\\\n    -m 1G \\\\\\n    -smp 4 \\\\\\n    -dtb bcm2710-rpi-3-b.dtb \\\\\\n    -kernel kernel8.img \\\\\\n    -append \\"rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1\\" \\\\\\n    -netdev user,id=net0,hostfwd=tcp::2222-:22 \\\\\\n    -device usb-net,netdev=net0 \\\\\\n    -sd 2024-05-03-raspios-bullseye-arm64-lite.img\\n```\\n\\nOptions in detail:\\n\\n- `-machine raspi3b`: use raspberry pi 3 machine.\\n- `-append`:\\n  - `console=ttyAMA0`: output the **VM** std to **QEMU** console.\\n  - `root=/dev/mmcblk0p2`: mount **real root filesystem** to `/dev/mmcblk0p2`(the second partition of `mmcblk0`) as we `-sd xx` will be mounted to `/dev/mmcblk0`.\\n- `-netdev user,id=net0,hostfwd=tcp::2222-:22`: network mapping host port `2222` to the **VM** `22`\\n- `-device usb-net,netdev=net0`: expose `netdev=net0` as `usb-net` in the raspberry pi 3 machine.\\n- `-sd 2024-05-03-raspios-bullseye-arm64-lite.img`: `sd` drive is available in the raspberry pi 3 machine.\\n\\n### Emulate Raspberry Pi 4 with `virt`\\n\\nWe will use generic virtual machine `virt` to act as `raspi4`, since there is no `raspi4` machine defined in QEMU official machines. However you can still use `raspi3` to act as `raspi4` as they are same!\\n\\n**Hardware Acceleration** can be enable in `virt` machine by using `-accel hvf` option in my **mac M1** host as it\'s **arm-based**.\\n\\nSo `virt` will bring high performance and increase efficiency!\\n\\nAfter tuning options and searching from many resources, the operational setting for QEMU to emulate is,\\n\\n1. Use `ubuntu-22.04.3-preinstalled-server-arm64+raspi.img`, of which the default user is `ubuntu` and password is `ubuntu`.\\n\\n```sh\\nkernel=\\"$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi-boot/vmlinuz\\"\\ninitrd=\\"$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi-boot/initrd.img\\"\\nimg=\\"$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi.img\\"\\n```\\n\\n\\n#### For `SCSI hard disk`\\n\\nThis storage device file will be named `/dev/sdX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -initrd $initrd \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0\\" \\\\\\n    -drive file=$img,format=raw,if=none,id=drive0 \\\\\\n    -device virtio-scsi-pci,id=scsi \\\\\\n    -device scsi-hd,drive=drive0,bus=scsi.0 \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nOptions in detail:\\n\\n- `-accel hvf`: **hardware acceleration** in mac M1. Don\'t use in **x86_64** host.\\n- `-cpu host`: change to `-cpu cortex-a72` when no **hardware acceleration** available such as in **x86_64** host.\\n- `-append`\\n  - `root=/dev/sda2`: the second partition of the `ubuntu-22.04.3-preinstalled-server-arm64+raspi.img` disk image hold the real root filesystem.\\n- `-initrd $initrd`\\n  - the boot loader works using configuration like `vmlinuz initrd=initrd.img root=/dev/sda2`.\\n\\n#### For `virtual disk` storage device\\n\\nThis storage device file will be named `/dev/vdX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -initrd $initrd \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/vda2 rootfstype=ext4 rw console=ttyAMA0\\" \\\\\\n    -drive file=$img,format=raw,if=none,id=drive0 \\\\\\n    -device virtio-blk-pci,drive=drive0 \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\n#### For `NVMe` storage device\\n\\nThis storage device file will be named `/dev/nvmeX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/nvme0n1p2 rootfstype=ext4 rw console=ttyAMA0\\" \\\\\\n    -drive file=$img,format=raw,if=none,id=drive0 \\\\\\n    -device nvme,drive=drive0,serial=deadbeaf1 \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nOptions in detail:\\n\\n- no `-initrd $initrd`\\n  - the boot loader works using configuration like `vmlinuz root=/dev/nvme0n1p2`.\\n  - we directly mount the real filesystem `/dev/nvme0n1p2`, skipping to mount the **initial RAM disk**.\\n  - I test other type storage device must binding `-initrd $initrd` while there is no need for `NVME`. In my assumption, those `storage devices` need to be configured in the `initramfs`.\\n\\n#### For `usb storage`\\n\\nThis storage device file will be named `/dev/sdX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -cpu cortex-a57 \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -no-reboot \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -initrd $initrd \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda2 rootfstype=ext4 console=ttyAMA0 raid=noautodetect\\" \\\\\\n    -device usb-ehci \\\\\\n    -device usb-storage,drive=disk0 \\\\\\n    -drive file=$img,format=raw,if=none,id=disk0 \\\\\\n    -device virtio-net-pci,netdev=mynet \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22\\n```\\n\\nOptions in detail:\\n\\n- `-device usb-ehci`: usb bus -> PCI bus\\n- `-device usb-storage`: usb storage device -> usb bus\\n\\n## Test Raspberry Pi VM\\n\\nLog into the **Raspberry Pi** via `ssh` from the macOS host,\\n\\n```sh\\n\u276f ssh -p 2222 pi@localhost\\nThe authenticity of host \'[localhost]:2222 ([127.0.0.1]:2222)\' can\'t be established.\\nED25519 key fingerprint is SHA256:6igL6iaigBCszv8m6nyNl+tsB2siV/tL+TRQANC6nBw.\\nThis key is not known by any other names\\nAre you sure you want to continue connecting (yes/no/[fingerprint])? yes\\nWarning: Permanently added \'[localhost]:2222\' (ED25519) to the list of known hosts.\\npi@localhost\'s password: \\nLinux raspberrypi 6.1.21-v8+ #1642 SMP PREEMPT Mon Apr  3 17:24:16 BST 2023 aarch64\\n\\nThe programs included with the Debian GNU/Linux system are free software;\\nthe exact distribution terms for each program are described in the\\nindividual files in /usr/share/doc/*/copyright.\\n\\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\\npermitted by applicable law.\\nLast login: Fri Sep 22 16:30:58 2023\\n\\nSSH is enabled and the default password for the \'pi\' user has not been changed.\\nThis is a security risk - please login as the \'pi\' user and type \'passwd\' to set a new password.\\n\\npi@raspberrypi:~ $ \\n```\\n\\n## Resources\\n\\n[Emulating a Raspberry Pi in QEMU | InterruptEmulating a Raspberry Pi in QEMU](https://interrupt.memfault.com/blog/emulating-raspberry-pi-in-qemu)\\n\\n[How to emulate block devices with QEMU](https://blogs.oracle.com/linux/post/how-to-emulate-block-devices-with-qemu)\\n\\n[Emulation of block devices \u2014 Das U-Boot unknown version documentation](https://u-boot.readthedocs.io/en/latest/board/emulation/blkdev.html)"},{"id":"/how-to-cross-compilation","metadata":{"permalink":"/blog/how-to-cross-compilation","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-cross-compilation.mdx","source":"@site/../../blog/how-to-cross-compilation.mdx","title":"Exploring cross compilation: ARM on x86_64","description":"How to perform cross compilation","date":"2024-09-18T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"},{"inline":true,"label":"toolchain","permalink":"/blog/tags/toolchain"}],"readingTime":2.725,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"description":"How to perform cross compilation","keywords":["cross-compilation","project structure","toolchain"],"image":"https://i.imgur.com/mErPwqL.png","tags":["how-to","toolchain"],"date":"2024-09-18T00:00:00.000Z","authors":["frank"]},"unlisted":false,"prevItem":{"title":"QEMU Emulate Raspberry Pi 3 and 4","permalink":"/blog/qemu-raspberry-pi"},"nextItem":{"title":"Installing FFmpeg on Nvidia CUDA container","permalink":"/blog/ffmpeg-on-cuda-container"}},"content":"## Cross Compilation Anatomy\\n\\nCross-Compilation ecosystem involves the following components:\\n\\n- host system\\n  - cross-Compilation toolchain\\n    - cross compiler\\n    - cross linker\\n    - cross debugger\\n    - sysroot\\n      - target system library files\\n      - target system header files\\n      - target system other files\\n- target system\\n\\n\x3c!--truncate--\x3e\\n\\nCross-Compilation toolchain:\\n\\n- GCC\\n- Buildroot\\n- Yocto Project\\n- Crosstool-NG\\n- Linaro\\n- Clang/LLVM\\n\\n## GCC\\n\\nLet\'s explore what a toolchain is like and what are needed to build something for a `aarch64` platform on `x86_64` debian-like host.\\n\\n### Obtaining a cross-compilation toolchain for `aarch64`\\n\\nFor simplicity and in a super fast way, we will use a prebuilt and ready-on toolchain in `x86_64` Ubuntu.\\n\\n```sh\\napt install gcc make gcc-aarch64-linux-gnu binutils-aarch64-linux-gnu\\n```\\n\\n### Where is `cross compiler`\\n\\nWe see `cross compiler` binary type in host is `x86-64`,\\n\\n```sh\\n$ file /usr/bin/aarch64-linux-gnu-gcc-11\\n/usr/bin/aarch64-linux-gnu-gcc-11: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=b1112487d0dcb759db32e15b8f40f28a05484272, for GNU/Linux 3.2.0, stripped\\n```\\n\\n### Where is `sysroot`\\n\\nThe `sysroot` locates in `/usr/aarch64-linux-gnu`,\\n\\n```sh\\n$ tree --filelimit=100 /usr/aarch64-linux-gnu\\n/usr/aarch64-linux-gnu\\n\u251c\u2500\u2500 bin\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ar -> ../../bin/aarch64-linux-gnu-ar\\n\u2502\xa0\xa0 \u251c\u2500\u2500 as -> ../../bin/aarch64-linux-gnu-as\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ld -> ../../bin/aarch64-linux-gnu-ld\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ld.bfd -> ../../bin/aarch64-linux-gnu-ld.bfd\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ld.gold -> ../../bin/aarch64-linux-gnu-ld.gold\\n\u2502\xa0\xa0 \u251c\u2500\u2500 nm -> ../../bin/aarch64-linux-gnu-nm\\n\u2502\xa0\xa0 \u251c\u2500\u2500 objcopy -> ../../bin/aarch64-linux-gnu-objcopy\\n\u2502\xa0\xa0 \u251c\u2500\u2500 objdump -> ../../bin/aarch64-linux-gnu-objdump\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ranlib -> ../../bin/aarch64-linux-gnu-ranlib\\n\u2502\xa0\xa0 \u251c\u2500\u2500 readelf -> ../../bin/aarch64-linux-gnu-readelf\\n\u2502\xa0\xa0 \u2514\u2500\u2500 strip -> ../../bin/aarch64-linux-gnu-strip\\n\u251c\u2500\u2500 include  [139 entries exceeds filelimit, not opening dir]\\n\u2514\u2500\u2500 lib\\n    \u251c\u2500\u2500 Mcrt1.o\\n    \u251c\u2500\u2500 Scrt1.o\\n    \u251c\u2500\u2500 crt1.o\\n    \u251c\u2500\u2500 crti.o\\n    \u251c\u2500\u2500 crtn.o\\n    \u251c\u2500\u2500 gcrt1.o\\n    \u251c\u2500\u2500 grcrt1.o\\n    \u251c\u2500\u2500 ld-linux-aarch64.so.1\\n```\\n\\nAs you see, the `binutils-aarch64-linux-gnu` will install `binutils` tools in `/usr/aarch64-linux-gnu/bin`,\\n\\nThese `binutils` are also `x86_64` binaries,\\n\\n```sh\\n file $(readlink -f /usr/aarch64-linux-gnu/bin/ar)\\n/usr/bin/aarch64-linux-gnu-ar: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=4f75b6dc6fe5ae92c78a51e6479ca2c65bbf5335, for GNU/Linux 3.2.0, stripped\\n```\\n\\nWhile target libraries are `aarch64` type,\\n\\n```sh\\nfile /usr/aarch64-linux-gnu/lib/crt1.o\\n/usr/aarch64-linux-gnu/lib/crt1.o: ELF 64-bit LSB relocatable, ARM aarch64, version 1 (SYSV), for GNU/Linux 3.7.0, not stripped\\n```\\n\\n### Compile `hello.c`\\n\\n```sh\\n$ aarch64-linux-gnu-gcc-11 hello.c -o a.out\\n$ file a.out\\na.out: ELF 64-bit LSB pie executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, BuildID[sha1]=367c436db0697f16039d9249e4a4e809ef9e68b3, for GNU/Linux 3.7.0, not stripped\\n```\\n\\n## Clang/LLVM\\n\\n[Cross compilation with Clang and LLVM tools](https://static.linaro.org/connect/bkk19/presentations/bkk19-210.pdf)\\n\\n[Cross compiling made easy, using Clang and LLVM \xb7 mcilloni\'s blog](https://mcilloni.ovh/2021/02/09/cxx-cross-clang/)\\n\\n```sh\\napt install lld clang llvm\\n```\\n\\n```sh\\n$ wget https://releases.linaro.org/components/toolchain/binaries/7.5-2019.12/aarch64-linux-gnu/sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu.tar.xz\\n\\n$ tar -xvf sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu.tar.xz\\n\\n$ mv sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu aarch64-linux-gnu\\n```\\n\\n```sh\\n$ ll aarch64-linux-gnu\\ntotal 20K\\ndrwxr-xr-x 2 11827 9000 4.0K Dec  4  2019 etc\\ndrwxr-xr-x 3 11827 9000 4.0K Dec  4  2019 lib\\ndrwxr-xr-x 2 11827 9000 4.0K Dec  4  2019 sbin\\ndrwxr-xr-x 8 11827 9000 4.0K Dec  4  2019 usr\\ndrwxr-xr-x 3 11827 9000 4.0K Dec  4  2019 var\\n```\\n\\n\\n```sh\\n$ cat > hello.c << EOL\\n#include <stdio.h>\\nint main(int argc, char *argv[])\\n{\\n  printf(\\"Hello cross-compilation world!\\\\n\\");\\n  return 0;\\n}\\nEOL\\n```\\n\\n```sh\\nsysroot=~/Documents/sysroot/aarch64-linux-gnu/usr\\n```\\n\\n```sh\\nclang --target=aarch64-linux-gnu hello.c -o hello_aarch64 -v\\n```\\n\\n```sh\\nclang --target=aarch64-linux-gnu hello.c -o hello_aarch64 --sysroot=$sysroot -v\\n```\\n\\n```sh\\nclang --target=aarch64-linux-gnu  -fsanitize=undefined \\\\\\n    -fuse-ld=lld \\\\\\n    --rtlib=compiler-rt -stdlib=libc++ \\\\\\n    -nostdinc++ -nostdlib \\\\\\n    -I${sysroot}/usr/include/ \\\\\\n    -Wl,-L${sysroot}/usr/lib \\\\\\n    --sysroot=$sysroot \\\\\\n    --verbose \\\\\\n    hello.c -o hello\\n```\\n\\n## Resources\\n\\n[GCC Cross-Compiler - OSDev Wiki](https://wiki.osdev.org/GCC_Cross-Compiler)\\n\\n[GitHub - generia/buildroot-osx: Buidroot OSX - Use Buildroot on OSX natively without a Linux container.](https://github.com/generia/buildroot-osx)\\n\\n[crosstool-ng Documentation](https://crosstool-ng.github.io/docs/)\\n\\n[aarch64 workflows example](https://github.com/messense/homebrew-macos-cross-toolchains/blob/main/.github/workflows/aarch64.yml)"},{"id":"/ffmpeg-on-cuda-container","metadata":{"permalink":"/blog/ffmpeg-on-cuda-container","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/ffmpeg-on-cuda-container.mdx","source":"@site/../../blog/ffmpeg-on-cuda-container.mdx","title":"Installing FFmpeg on Nvidia CUDA container","description":"FFmpeg on CUDA Container","date":"2024-09-06T00:00:00.000Z","tags":[{"inline":true,"label":"ffmpeg","permalink":"/blog/tags/ffmpeg"},{"inline":true,"label":"docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"cuda","permalink":"/blog/tags/cuda"}],"readingTime":1.64,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/ffmpeg-on-cuda-container.mdx"},"authors":["frank"],"tags":["ffmpeg","docker","cuda"],"description":"FFmpeg on CUDA Container","keywords":["FFmpeg on CUDA Container"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-09-06T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Exploring cross compilation: ARM on x86_64","permalink":"/blog/how-to-cross-compilation"},"nextItem":{"title":"Making your own Dotfiles for your sake","permalink":"/blog/how-to-dotfiles"}},"content":"This documentation describes to install `FFmpeg` on `nvidia/cuda` **container** to use the **Nvidia GPU** to accelerate encoding.\\n\\nIf you want to know [how to install FFmpeg with NVIDIA GPU on Linux](https://www.cyberciti.biz/faq/how-to-install-ffmpeg-with-nvidia-gpu-acceleration-on-linux/), go to see that.\\n\\n\\n**FFmpeg** can support hardware-based decoding and encoding for Nvidia GPU card. With the help of Nvidia GPU, `h264_nvenc` can lead encoding speed with **5x** faster than `libx264` in **GTX1080** card.\\n\\nLet\'s see how to install everything one by one on the **Nvidia CUDA Docker** container `nvidia/cuda:12.2.0-devel-ubuntu20.04`, in which CUDA toolkit and GPU driver are already included.\\n\\n\x3c!--truncate--\x3e\\n\\n:::note\\n> It must use `nvidia/cuda:xxx-devel-xxx` image to build `FFmpeg`, because the `dev` image contain all the necessary libraries.\\n:::\\n\\n## Prerequisites\\n\\nMake sure **Nvidia GPU Driver** is installed in your host machine! As it will be mounted into the **container**. \\n\\nUse `ldconfig` to check if the required Nvidia GPU driver libraries are available inside the container. Such as,\\n\\n```sh\\nldconfig -p | grep libcuda\\n```\\n\\n:::note\\n> When running in the `nvidia/cuda` Docker container, what Nvidia libraries(from the host machine) should be mounted inside the container are specified by the `NVIDIA_DRIVER_CAPABILITIES` env variable, see [driver-capabilities](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#driver-capabilities). Here for `FFmpeg` to employ GPU, it should be included at least as `NVIDIA_DRIVER_CAPABILITIES=video,utility`.\\n:::\\n\\n## Step by Step\\n\\n```sh\\ndocker run --rm --runtime=nvidia \\\\\\n    -e NVIDIA_VISIBLE_DEVICES=all \\\\\\n    -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \\\\\\n    nvidia/cuda nvidia-smi\\n```\\n\\n```sh\\ndocker run --rm --runtime=nvidia \\\\\\n    -e NVIDIA_VISIBLE_DEVICES=all \\\\\\n    -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \\\\\\n    nvidia/cuda bash\\n```\\n\\n## Complete Dockerfile\\n\\n```js reference\\nhttps://github.com/liviaerxin/hello-dockerfile/blob/main/nvidia-cuda-ffmpeg/Dockerfile\\n```\\n\\n## Known issues\\n\\nNvidia Docker encoding stops after long running time with such error message: `CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected`.\\n\\n[[Issue]: NVidia Docker transcoding randomly stops working after 5 minutes to 4 hours later. \xb7 Issue #9287 \xb7 jellyfin/jellyfin \xb7 GitHub](https://github.com/jellyfin/jellyfin/issues/9287)\\n\\nPossible solution:\\n\\nEdit `/etc/defautls/grub`,\\n\\n```sh\\nGRUB_CMDLINE_LINUX_DEFAULT=\\"quiet splash systemd.unified_cgroup_hierarchy=0\\"\\n```\\n\\nThen run `update-grub` and reboot.\\n\\n## References\\n\\n[Using FFmpeg with NVIDIA GPU Hardware Acceleration - NVIDIA Docs](https://docs.nvidia.com/video-technologies/video-codec-sdk/12.0/ffmpeg-with-nvidia-gpu/index.html)\\n\\n[NVIDIA FFmpeg Transcoding Guide | NVIDIA Technical Blog](https://developer.nvidia.com/blog/nvidia-ffmpeg-transcoding-guide/)\\n\\n[User Guide \u2014 container-toolkit 1.13.5 documentation](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/user-guide.html)\\n\\n\\n[wiki cuda](../docs/wiki/wiki-cuda.mdx)"},{"id":"/how-to-dotfiles","metadata":{"permalink":"/blog/how-to-dotfiles","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-dotfiles.md","source":"@site/../../blog/how-to-dotfiles.md","title":"Making your own Dotfiles for your sake","description":"How to Create Dotfiles for Your Setup","date":"2024-06-26T00:00:00.000Z","tags":[{"inline":true,"label":"dotfiles","permalink":"/blog/tags/dotfiles"},{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"}],"readingTime":0.16,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"sidebar_label":"how to dotfiles","description":"How to Create Dotfiles for Your Setup","keywords":["dotfiles"],"image":"https://i.imgur.com/mErPwqL.png","tags":["dotfiles","how-to"],"date":"2024-06-26T00:00:00.000Z","authors":["frank"]},"unlisted":false,"prevItem":{"title":"Installing FFmpeg on Nvidia CUDA container","permalink":"/blog/ffmpeg-on-cuda-container"},"nextItem":{"title":"Playing with unicode in deep","permalink":"/blog/how-to-unicode"}},"content":"[Tutorials - dotfiles.github.io](http://dotfiles.github.io/tutorials/)\\n\\n[Getting started with dotfilesFrontend Ramblings RSS feedThe content of this website on GitHubMy Mastodon profileMy Twitter profileShare this article on TwitterShare this article on Hacker News](https://www.webpro.nl/articles/getting-started-with-dotfiles)\\n\\n\x3c!-- truncate --\x3e"},{"id":"/how-to-unicode","metadata":{"permalink":"/blog/how-to-unicode","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-unicode.mdx","source":"@site/../../blog/how-to-unicode.mdx","title":"Playing with unicode in deep","description":"Playing with Unicode in deep","date":"2023-12-08T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"},{"inline":true,"label":"unicode","permalink":"/blog/tags/unicode"}],"readingTime":5.685,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["how-to","unicode"],"description":"Playing with Unicode in deep","keywords":["how-to","UTF8","encode"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-12-08T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Making your own Dotfiles for your sake","permalink":"/blog/how-to-dotfiles"},"nextItem":{"title":"Discovering QEMU","permalink":"/blog/how-to-qemu"}},"content":"The smallest unit of all texts we see on the screen is one character. But you may wonder about:\\n\\n1. How one character is displayed on the screen?\\n2. How one character is kept in memory or disk in binary format(0 or 1)?\\n\\nLet\'s dive into the **Unicode** to solve these questions.\\n\\nIn Unicode, a character maps to something called code point which is a magic number written as hex like: `U+20AC` and is still just a abstract layer.\\n\\n| Layer       | Representation                      |\\n|-------------|-------------------------------------|\\n| screen      | glyph                               |\\n| abstraction | unicode character                   |\\n| abstraction | unicode code point                  |\\n| disk        | variable-length bytes(1 to 4 bytes) |\\n\\nHow that code point is represented in memory or on disk?\\n\\n`UTF-8`, `UTF-16`, and `UTF-32` help translate unicode code point into binary data in 8-bit bytes which can be saved in disk or be transported in network.\\n\\n`UTF-8` is character-to-bytes(1 to 4 bytes) encoding standard across almost all system and application.\\n\\n\x3c!--truncate--\x3e\\n\\n## FAQ\\n\\n### How a character is displayed on the screen?\\n\\nsoftware maps each character to its glyph(a grid of pixels), draw these pixels onto the screen.\\n\\n### How to find out whether the file uses UTF-8 or ASCII or other encoding schemas?\\n\\nIt\'s not always foolproof because there is no universal mandate or requirement that all files must specify their encoding. But it\'s a good practice to add BOM(Byte Order Mark) at the beginning of a UTF-8 encoded file.\\n\\n### Can I set UTF-16 as locale in Linux?\\n\\nNo, you cannot. Linux use `UTF-8` encoding which is compatible with `ASCII`.\\n\\n### What happens when printing a UTF-16 file in Linux?\\n\\n```sh\\n# >>> \'\u20ac\'.encode(\\"utf16\\") -> b\'\\\\xff\\\\xfe\\\\xac \'\\n$ echo -n -e \\\\\\\\xff\\\\\\\\xfe\\\\\\\\xac\\\\\\\\x20 > a.txt\\n$ hexdump -C a.txt\\n00000000  ff fe ac 20                                       |... |\\n00000004\\n$ file a.txt\\na.txt: Unicode text, UTF-16, little-endian text, with no line terminators\\n$ cat a.txt\\n\ufffd\ufffd\ufffd\\n$ iconv -f UTF-16LE -t UTF-8 a.txt\\n\u20ac\\n```\\n\\n### How can I check a UTF-8 file has a `BOM`?\\n\\nCreate a file without `BOM`,\\n\\n```py\\n>>> f.flush()\\n>>> b\'\\\\xe2\\\\x82\\\\xac\'.decode()\\n\'\u20ac\'\\n>>> \'\u20ac\'.encode()\\nb\'\\\\xe2\\\\x82\\\\xac\'\\n>>> bom=b\\"\\\\xef\\\\xbb\\\\xbf\\"\\n>>> f=open(\\"a.txt\\", \\"wb+\\")\\n>>> f.write(b\'\\\\xe2\\\\x82\\\\xac\')\\n3\\n>>> f.flush()\\n```\\n\\n```sh\\n$ file a.txt\\na.txt: Unicode text, UTF-8 text, with no line terminators\\n```\\n\\nCreate a `BOM` adhere file,\\n\\n```py\\n>>> f.seek(0)\\n0\\n>>> f.truncate(0)\\n0\\n>>> f.write(b\'\\\\xef\\\\xbb\\\\xbf\\\\xe2\\\\x82\\\\xac\')\\n6\\n>>> f.flush()\\n```\\n\\n```sh\\n$ file a.txt\\na.txt: Unicode text, UTF-8 (with BOM) text, with no line terminators\\n$ hexdump -C a.txt\\n00000000  ef bb bf e2 82 ac                                 |......|\\n00000006\\n```\\n\\n### Why we can copy and paste the unicode characters into a shell?\\n\\nWhen we do copying on the screen, we\'re copying the character\'s UTF8 encoded **bytes** which is in the memory, not the **code point**.\\n\\n```sh\\n# b\'\\\\xe2\\\\x82\\\\xac\'.decode() -> \'\u20ac\'\\n$ echo -e \\\\\\\\xe2\\\\\\\\x82\\\\\\\\xac | xclip -selection clipboard\\n```\\n\\nThen you can use your mouse right click to copy to the shell and you will see `\u20ac`.\\n\\n### How a string is stored in memory when Python running?\\n\\n## Unicode in JSON\\n\\nJSON(natively a text format) support the unicode character to be escaped or not. When **being escaped**, the character will be replaced with the unicode code point, then which will be represented in 6 or 8 ascii characters occupying 6 or 8 bytes. When **not being escaped**, the character will be represented as just one unicode character as itself occupying 1 to 4 bytes if using UTF-8.\\n\\nEscaping will cost more storage but will be compatible in ASCII-only environments, as escaping force all characters to be ASCII characters.\\n\\nCase 1: Characters escaped,\\n\\n```py\\n>>> import json\\n>>> b=b\'{\\"text\\": \\"\\\\u4f60\\\\u597d\\"}\'\\n>>> json.loads(b)\\n{\'text\': \'\u4f60\u597d\'}jsn\\n>>> json.dumps(json.loads(b))\\n\'{\\"text\\": \\"\\\\\\\\u4f60\\\\\\\\u597d\\"}\'\\n>>> json.dumps(json.loads(b), ensure_ascii=False)\\n\'{\\"text\\": \\"\u4f60\u597d\\"}\'\\n```\\n\\n```py\\n>>> f=open(\\"a.txt\\", \\"w+\\")\\n>>> f.write(json.dumps(json.loads(b)))\\n24\\n>>> f.flush()\\n```\\n\\n```sh\\n$ cat a.txt\\n{\\"text\\": \\"\\\\u4f60\\\\u597d\\"}#\\n$  hexdump -C a.txt\\n00000000  7b 22 74 65 78 74 22 3a  20 22 5c 75 34 66 36 30  |{\\"text\\": \\"\\\\u4f60|\\n00000010  5c 75 35 39 37 64 22 7d                           |\\\\u597d\\"}|\\n00000018\\n```\\n\\nCase 2: Characters not escaped,\\n\\n```py\\n>>> f.seek(0)\\n0\\n>>> f.truncate(0)\\n0\\n>>> f.write(json.dumps(json.loads(b), ensure_ascii=False))\\n14\\n>>> f.flush()\\n```\\n\\n```sh\\n$ cat a.txt\\n{\\"text\\": \\"\u4f60\u597d\\"}#\\n$ hexdump -C a.txt\\n00000000  7b 22 74 65 78 74 22 3a  20 22 e4 bd a0 e5 a5 bd  |{\\"text\\": \\"......|\\n00000010  22 7d                                             |\\"}|\\n00000012\\n```\\n\\n## Base64\\n\\nBase64 is binary-to-text encoding schema which make bytes data to be represented in ASCII characters to be human readable.\\n\\n## Python \\n\\n## C application\\n\\nLet\'s have a look at how the **Unicode** is represented in a `C` executable file.\\n\\n1. `char`\\n\\n```sh\\ncat > unicode.c << EOL\\n#include <stdio.h>\\n\\nint main(){\\n    printf(\\"Hello, World \u4f60\u597d\ud83e\udd28!\\\\n\\");\\n    return 0;\\n}\\nEOL\\n```\\n\\n```sh\\ngcc unicode.c -o unicode.out\\n```\\n\\n```sh\\nroot@112b172acfff:/workspaces/liviaerxin.github.io/# hexdump -C unicode.out | grep -A3 \\"Hello, World\\"\\n00002000  01 00 02 00 48 65 6c 6c  6f 2c 20 57 6f 72 6c 64  |....Hello, World|\\n00002010  20 e4 bd a0 e5 a5 bd f0  9f a4 a8 21 00 00 00 00  | ..........!....|\\n00002020  01 1b 03 3b 34 00 00 00  05 00 00 00 00 f0 ff ff  |...;4...........|\\n00002030  68 00 00 00 20 f0 ff ff  90 00 00 00 30 f0 ff ff  |h... .......0...|\\n```\\n\\nView each character\'s **UTF8** encoding respectively,\\n```py\\n# utf-8 encoding bytes\\n>>> \\"\u4f60\\".encode()\\nb\'\\\\xe4\\\\xbd\\\\xa0\'\\n>>> \\"\u597d\\".encode()\\nb\'\\\\xe5\\\\xa5\\\\xbd\'\\n>>> \\"\ud83e\udd28\\".encode()\\nb\'\\\\xf0\\\\x9f\\\\xa4\\\\xa8\'\\n```\\n\\nSo  `char` in the C output file stores the UTF8 encoding **bytes**, not the code points.\\n\\n2. `wide char`,\\n\\n```sh\\ncat > unicode.c << EOL\\n#include <stdio.h>\\n#include <wchar.h>\\n#include <locale.h>\\n\\nint main(int argc, char *argv[])\\n{\\n    setlocale(LC_ALL, \\"C.UTF-8\\");\\n    wchar_t* msg = L\\"Hello, World \u4f60\u597d\ud83e\udd28!\\";\\n    printf(\\"%ls\\\\n\\", msg);\\n    return 0;\\n}\\nEOL\\n```\\n\\n```sh\\nroot@112b172acfff:/workspaces/liviaerxin.github.io/# hexdump -C unicode.out\\n00002000  01 00 02 00 00 00 00 00  43 2e 55 54 46 2d 38 00  |........C.UTF-8.|\\n00002010  48 00 00 00 65 00 00 00  6c 00 00 00 6c 00 00 00  |H...e...l...l...|\\n00002020  6f 00 00 00 2c 00 00 00  20 00 00 00 57 00 00 00  |o...,... ...W...|\\n00002030  6f 00 00 00 72 00 00 00  6c 00 00 00 64 00 00 00  |o...r...l...d...|\\n00002040  20 00 00 00 60 4f 00 00  7d 59 00 00 28 f9 01 00  | ...`O..}Y..(...|\\n```\\n\\n```py\\n# unicode code point\\n>>> hex(ord(\\"H\\"))\\n\'0x48\'\\n>>> hex(ord(\\"\u4f60\\"))\\n\'0x4f60\'\\n>>> hex(ord(\\"\u597d\\"))\\n\'0x597d\'\\n>>> hex(ord(\\"\ud83e\udd28\\"))\\n\'0x1f928\'\\n```\\n\\n`wchar` in the C output file stores the **code point**(also in **little endian**), not the UTF8 encoding **bytes**.\\n\\nIn conclusion, `char` and `wchar` lead different encoding in **C**.\\n\\n## References\\n\\n[The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) \u2013 Joel on Software](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\\n\\n[Pragmatic Unicode | Ned Batchelder](https://nedbatchelder.com/text/unipain.html)"},{"id":"/how-to-qemu","metadata":{"permalink":"/blog/how-to-qemu","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-qemu.mdx","source":"@site/../../blog/how-to-qemu.mdx","title":"Discovering QEMU","description":"Get started with qemu","date":"2023-09-19T00:00:00.000Z","tags":[{"inline":true,"label":"vm","permalink":"/blog/tags/vm"},{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"}],"readingTime":3.725,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"description":"Get started with qemu","keywords":["qemu","how-to"],"image":"https://i.imgur.com/mErPwqL.png","tags":["vm","how-to"],"date":"2023-09-19T00:00:00.000Z","authors":["frank"]},"unlisted":false,"prevItem":{"title":"Playing with unicode in deep","permalink":"/blog/how-to-unicode"},"nextItem":{"title":"Managing intel VROC RAID on ubuntu","permalink":"/blog/raid-intel-vroc"}},"content":"Learning and using the **QEMU** help me understand how the linux operating system works including fields:\\n\\n1. Linux boot process.\\n2. Cross compile for target system(such as arm64) on host system(such as x86_64), and test the binary.\\n\\n\x3c!--truncate--\x3e\\n\\n## OS image Resources\\n\\n- [Ubuntu OS Images](https://cdimage.ubuntu.com/)\\n- [Debian OS Images](https://cdimage.debian.org/)\\n- [Raspberry PI OS Images](https://downloads.raspberrypi.org/)\\n\\n### QEMU Keyboard shortcuts\\n\\n- Switch between QEMU monitor console and the guest non-graphic OS\\n  - `CTRL+a c`\\n- Exit the guest non-graphic OS\\n  - `CTRL+a x`\\n- Switch between QEMU monitor console and the guest graphic OS\\n  - `CTRL+ALT+1`, `CTRL+ALT+2`\\n\\n### Discover the VM device tree\\n\\nEnter the QEMU monitor console, using `info qtree` command,\\n\\n```sh\\n$ info qtree\\n\\n dev: gpex-pcihost, id \\"\\"\\n    ...\\n    bus: pcie.0\\n      type PCIE\\n      dev: virtio-scsi-pci, id \\"\\"\\n        ...\\n        bus: virtio-bus\\n          type virtio-pci-bus\\n          dev: virtio-scsi-device, id \\"\\"\\n            ...\\n            bus: scsi.0\\n              type SCSI\\n              dev: scsi-hd, id \\"\\"\\n                drive = \\"hd\\"\\n                ...\\n      dev: nvme, id \\"\\"\\n        drive = \\"drive0\\"\\n        ...\\n        bus: nvme-bus.0\\n          type nvme-bus\\n      dev: virtio-net-pci, id \\"\\"\\n        ...\\n        bus: virtio-bus\\n          type virtio-pci-bus\\n          dev: virtio-net-device, id \\"\\"\\n            ...\\n\\n```\\n\\n### List supported devices\\n\\n```sh\\n$ qemu-system-aarch64 -device help\\n$ qemu-system-aarch64 -device scsi-hd,help\\n```\\n\\n## Create disk image\\n\\n```sh\\nqemu-img create -f raw ubuntu.raw 20G\\nqemu-img create -f qcow2 ubuntu.qcow2 20G\\n```\\n\\nQEMU can boot from 3 ways:\\n\\n- BIOS in default\\n- Linux kernel and initrad\\n- UEFI\\n\\nFor **UEFI** boot, the `-bios` option should be used alongside `UEFI` firmware(`OVMF.fd` file) being provided to help QEMU do `UEFI` boot. For instance it is like: `-bios OVMF.fd`.\\n\\nGet a prebuilt `OVMF` file from the [OVMF](https://www.kraxel.org/repos/jenkins/edk2/).\\n\\n## BIOS boot\\n\\nTest entering BIOS,\\n\\n```sh\\nqemu-system-x86_64 -monitor stdio -m 1G\\n```\\n\\nThen QEMU will show like this,\\n\\n![BIOS](../attachments/images/bios.png)\\n\\n\\n## Kernel boot\\n\\n## UEFI boot\\n\\n### Test UEFI boot\\n\\naarch64,\\n\\n```sh\\nefi=\\"$PWD/UEFI/aarch64/QEMU_EFI.fd\\"\\n\\nqemu-system-aarch64 -monitor stdio -M virt -cpu cortex-a57 -m 1G -net none -bios $efi\\n\\nqemu-system-aarch64 -nographic -M virt -cpu cortex-a57 -m 1G -net none -bios $efi\\n```\\n\\nx86_64,\\n\\n```sh\\nefi=\\"$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd\\"\\n\\nqemu-system-x86_64 -monitor stdio -m 1G -net none -bios $efi\\n```\\n\\nThen QEMU will drop into the **UEFI** shell, like this following image show,\\n\\n![efi](../attachments/images/efi.png)\\n\\nOptions in detail:\\n\\n- `-nographic`: Don\'t create a video for the VM, just use the terminal.\\n:::info\\nquit QEMU: `Ctrl+A X`.  \\nenter QEMU monitor console: `Ctrl+A C`.  \\nsee at [How to quit the QEMU monitor when not using a GUI?](https://superuser.com/questions/1087859/how-to-quit-the-qemu-monitor-when-not-using-a-gui)\\n:::\\n\\n- `-monitor stdio`: Put QEMU monitor console in the terminal, while guest OS kept in created video device.\\n:::info\\nswitch between monitor console and guest OS: `Ctrl+Alt+1` or `Ctrl+Alt+2`.\\n:::\\n\\n- `-net none`: Disable iPXE.\\n\\n### Boot x86_64 ISO image\\n\\nBoot x86_64 image in Windows,\\n\\n```sh\\nefi=\\"$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd\\"\\niso=ubuntu-22.04-live-server-amd64.iso\\n```\\n\\n:::note\\n`ubuntu-**-amd64.iso` support both **UEFI** and Legacy **BIOS** boot, QEMU use **BIOS** when the option `-bios` is not specified!\\n:::\\n\\n1. Create a disk image to install the ubuntu OS,\\n\\n```sh\\nqemu-img create -f qcow2 ubuntu-image.qcow2 20G\\n```\\n\\n2. Boot to run the Ubuntu OS\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -monitor stdio \\\\\\n    -accel whpx \\\\\\n    -m 8G \\\\\\n    -smp 4 \\\\\\n    -drive file=ubuntu-image.qcow2 \\\\\\n    -bios $efi \\\\\\n    -cdrom $iso\\n```\\n\\nOptions in details,\\n\\n- `-accel whpx`: use hardware acceleration\\n\\n3. [?]Boot the installed Ubuntu OS\\n\\n```sh\\n# Install OS into a disk image\\nqemu-system-x86_64 \\\\\\n    -accel whpx \\\\\\n    -m 8G \\\\\\n    -smp 4 \\\\\\n    -bios $efi \\\\\\n    -drive file=ubuntu.qcow2,format=qcow2,if=virtio \\\\\\n```\\n\\n### Boot aarch64 ISO image\\n\\nEmulate aarch64 ISO image in Windows,\\n\\n```sh\\nefi=\\"$PWD/UEFI/aarch64/QEMU_EFI.fd\\"\\niso=\\"ubuntu-22.04-live-server-arm64.iso\\"\\n\\nqemu-system-aarch64 \\\\\\n    -monitor stdio \\\\\\n    -machine virt \\\\\\n    -cpu cortex-a57 \\\\\\n    -m 4G \\\\\\n    -smp 4 \\\\\\n    -drive file=ubuntu.qcow2,format=raw,if=virtio \\\\\\n    -bios $efi \\\\\\n    -cdrom $iso\\n```\\n\\nEmulate aarch64 ISO image in mac M1,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -monitor stdio \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -m 4G \\\\\\n    -smp 4 \\\\\\n    -drive file=ubuntu.qcow2,format=raw,if=virtio \\\\\\n    -bios $efi \\\\\\n    -cdrom $iso\\n``` \\n\\nOptions in details,\\n\\n- `-accel hvf`: use hardware acceleration in mac M1.\\n- `-cpu host`: use mac M1 arm CPU.\\n\\n### Boot a preinstalled image\\n\\n```sh\\n# linux\\nfdisk -l ubuntu-core-22-arm64+raspi.img\\n\\n# osx\\nhdiutil imageinfo ubuntu-core-22-arm64+raspi.img\\n```\\n\\n```sh\\nkernel=\\"$PWD/TinyCore/boot/vmlinuz64\\"\\ninitrd=$\\"$PWD/TinyCore/boot/corepure64.gz\\"\\nimg=$\\"$PWD/TinyCorePure64-14.0.iso\\"\\nefi=\\"$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd\\"\\n\\nkernel=\\"$PWD/linux_qemu/x86_64/bzImage\\"\\nvmlinuz=\\"$PWD/linux_qemu/x86_64/vmlinux\\"\\ninitrd=\\"$PWD/linux_qemu/x86_64/rootfs.ext2\\"\\nimg=\\"$PWD/linux_qemu/x86_64/rootfs.ext2\\"\\n```\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -initrd $img \\\\\\n    -append \\"console=ttyS0\\" \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\n### Boot linux kernel\\n\\n## Troubleshooting\\n\\n## References\\n\\n[UEFI, PC boot process and UEFI with QEMU | joonas.fi](https://joonas.fi/2021/02/uefi-pc-boot-process-and-uefi-with-qemu/)\\n\\nhttps://medium.com/@ThyCrow/compiling-the-linux-kernel-and-creating-a-bootable-iso-from-it-6afb8d23ba22\\n\\nhttps://levelup.gitconnected.com/probably-the-simplest-way-to-install-debian-ubuntu-in-qemu-2db6afde27ef\\n\\n[UEFI on AARCH64 | Welcome to the Mike\u2019s homepage!](https://krinkinmu.github.io/2020/11/21/EFI-aarch64.html)\\n\\n[OVMF \xb7 tianocore/tianocore.github.io Wiki \xb7 GitHub](https://github.com/tianocore/tianocore.github.io/wiki/OVMF)\\n\\n[Arm64Qemu - Debian Wiki](https://wiki.debian.org/Arm64Qemu)\\n\\nhttp://cdn.kernel.org/pub/linux/kernel/people/will/docs/qemu/qemu-arm64-howto.html\\n\\nhttps://futurewei-cloud.github.io/ARM-Datacenter/qemu/how-to-launch-aarch64-vm/\\n\\n[Build an aarch64 UEFI image for QEMU - lyan](https://xryan.net/p/212)"},{"id":"/raid-intel-vroc","metadata":{"permalink":"/blog/raid-intel-vroc","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/raid-intel-vroc.mdx","source":"@site/../../blog/raid-intel-vroc.mdx","title":"Managing intel VROC RAID on ubuntu","description":"Setup Intel VROC RAID on Ubuntu","date":"2023-08-29T00:00:00.000Z","tags":[{"inline":true,"label":"raid","permalink":"/blog/tags/raid"},{"inline":true,"label":"ubuntu","permalink":"/blog/tags/ubuntu"}],"readingTime":6.27,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/wiki-ffmpeg.md"},"authors":["frank"],"description":"Setup Intel VROC RAID on Ubuntu","keywords":["Setup Intel VROC RAID on Ubuntu"],"image":"https://i.imgur.com/mErPwqL.png","tags":["raid","ubuntu"],"date":"2023-08-29T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Discovering QEMU","permalink":"/blog/how-to-qemu"},"nextItem":{"title":"Managing RAID on ubuntu","permalink":"/blog/raid-on-ubuntu"}},"content":"This document will present how to create and manage **Intel VROC RAID** on Ubuntu with `mdadm` utility(It should also work in other Linux).\\n\\nFor setting up **Intel VROC RAID** on Ubuntu in `BIOS`, go to see [VROC Ubuntu Setup](https://www.intel.com/content/dam/support/us/en/documents/memory-and-storage/ssd-software/VROC-Ubuntu-Setup-UserGuide-342787-US.pdf).\\n\\nFor creating **software RAID** on Ubuntu, go to see:\\n\\n[Ubuntu RAID](./raid-on-ubuntu.mdx).\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nOn the premise machine, there are 2 NVMe SSDs and 8 SATA hard drives(HDDs), and also it ships with a in-box hardware-assisted RAID controller(**Intel VROC**) on the Intel CPU, which is supposed to keep overall advantages over **software RAID**.\\n\\nFor me, I would like to use these 8 HDDs(`sda`, `sdb`, ..., `sdh`) to store data for long time, while retaining the balance between redundancy and performance. So here **RAID 5**(Stripping with Parity) comes into my mind.\\n\\nTo leverage the power of **Intel VROC** in Ubuntu(Linux), you also need the `mdadm` command line tool to manage intel VROC which support RAID 0, RAID 1, RAID 5 and RAID 10\\n\\n:::note\\nIn my understanding, the intel VROC register in system with the common interface with `mdadm`, so the `mdadm` software can operate it. And running command will show the `mdadm` is using intel VROC,\\n\\n```sh\\n$ sudo mdadm --detail-platform\\n\\n       Platform : Intel(R) Virtual RAID on CPU\\n        Version : 8.0.3.1002\\n    RAID Levels : raid0 raid1 raid10 raid5\\n    Chunk Sizes : 4k 8k 16k 32k 64k 128k\\n    2TB volumes : supported\\n      2TB disks : supported\\n      Max Disks : 8\\n    Max Volumes : 2 per array, 8 per controller\\n I/O Controller : /sys/devices/pci0000:00/0000:00:17.0 (SATA)\\n          Port7 : /dev/sdh (ZR909K07)\\n          Port6 : /dev/sdg (ZV70BN24)\\n          Port3 : /dev/sdd (ZV70BD3T)\\n          Port4 : /dev/sde (ZR909Q89)\\n          Port1 : /dev/sdb (ZRT0S2FM)\\n          Port5 : /dev/sdf (ZR9099MM)\\n          Port2 : /dev/sdc (ZR909AGN)\\n          Port0 : /dev/sda (ZV70BMH9)\\n\\n       Platform : Intel(R) Virtual RAID on CPU\\n        Version : 8.0.3.1002\\n    RAID Levels : raid0 raid1 raid10\\n    Chunk Sizes : 4k 8k 16k 32k 64k 128k\\n    2TB volumes : supported\\n      2TB disks : supported\\n      Max Disks : 96\\n    Max Volumes : 2 per array, 24 per controller\\n 3rd party NVMe : supported\\n I/O Controller : /sys/devices/pci0000:8d/0000:8d:00.5 (VMD)\\n NVMe under VMD : /dev/nvme0n1 (633FC084FCVK)\\n NVMe under VMD : /dev/nvme1n1 (633FC0DEFCVK)\\n I/O Controller : /sys/devices/pci0000:6f/0000:6f:00.5 (VMD)\\n I/O Controller : /sys/devices/pci0000:51/0000:51:00.5 (VMD)\\n```\\n\\n:::\\n\\n:::info\\n\\nInstall Ubuntu Server on RAID:\\nUbuntu Server Image has inbox `mdadm` utilities and `VMD` drivers(which enable intel VROC functionalities), so it is quite convenient to create the RAID 1 on 2 SSDs either in BIOS stage(for intel VROC only) or in storage layer step during OS installation stage(software RAID), then install Ubuntu Server OS on the RAID 1.\\n\\nAfter creating the RAID 1 via intel VROC in BIOS, Ubuntu Server installation can detect the RAID created by VROC in step when set up the storage layer.\\n\\nIf you skip BIOS to create RAID during OS installation, remember to add `-e isms` when using `mdadm` to create RAID(you can enter the terminal, do ``) otherwise the RAID is software based and does not apply VROC.\\n\\nInstall Ubuntu Desktop on RAID:\\nUbuntu Desk Image does not ship the `mdadm` tool, so it is nearly impossible to create RAID and install Ubuntu Desktop OS on the RAID(however this one [Install Ubuntu 20.04 desktop with RAID 1 and LVM on machine with UEFI BIOS](https://askubuntu.com/questions/1299978/install-ubuntu-20-04-desktop-with-raid-1-and-lvm-on-machine-with-uefi-bios) from stackoverflow seems to be successful)\\n:::\\n\\n## Set up RAID 5 array\\n\\nHere, I use 8 disks: `/dev/sda`, `/dev/sdb`, ..., `/dev/sdh` to create **RAID 5** array and mount it for use in practice.\\n\\n### Create RAID array\\n\\nWhen creating RAID array, **Intel VROC** is different with **software RAID** array creation as an additional container is needed to create firstly. Inside the container, some information is labelled into the drives for Intel VROC controller to recognize them.\\n\\n1. Create RAID Container with Intel IMSM Metadata\\n\\nthe total number of drives is 8 and `-e imsm`.\\n\\n```sh\\nsudo mdadm --create /dev/md/imsm0 /dev/sd[a-h] -n 8 -e imsm\\n```\\n\\n2. Then, Create a RAID array in the `/dev/md/imsm0` container using total 8 drives with **RAID 5**.\\n\\n```sh\\nsudo mdadm --create /dev/md/md0 /dev/md/imsm0 -l 0 -n 2\\n```\\n\\n### Mount the RAID array for use\\n\\nAfter you create the RAID array in above step, all partitions and data will be erased from all individual disks.\\n\\nThe RAID array is treated as a **logical drive** now.\\n\\n1. Create a `ext4` filesystem on the RAID array\\n\\n```sh\\nsudo mkfs.ext4 -F /dev/md/md0\\n```\\n\\n2. Mount the RAID array\\n\\n```sh\\nsudo mkdir -p /mnt/md0\\n\\nsudo mount /dev/md/md0 /mnt/md0\\n```\\n\\n### Save RAID array configuration\\n\\nTo make sure that the RAID array is reassembled and mounted automatically after reboot, we will have to add some necessary information into `/etc/mdadm/mdadm.conf` and `/etc/fstab`.\\n\\n1. Scan active array and append into `/etc/mdadm/mdadm.conf` file with following:\\n\\n```sh\\nsudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf\\n```\\n\\n2. Update `initramfs`, so the array will be available at early boot:\\n\\n```sh\\nsudo update-initramfs -u\\n```\\n\\n3. Add mount options to `/etc/fstab`, you can use `UUID=xxxx` instead of the `/dev/md0`.\\n\\n```sh\\necho \'/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0\' | sudo tee -a /etc/fstab\\n```\\n\\n## Remove RAID Array\\n\\n### [Optional] Umount the array from filesystem\\n\\nUmount the array from filesystem if mounted,\\n\\n```sh\\nsudo umount /dev/md/md0\\n```\\n\\n### Stop RAID container and array\\n\\n```sh\\n# Stop RAID container\\nsudo mdadm --stop /dev/md/imsm0\\n# Stop RAID array\\nsudo mdadm --stop /dev/md/md0\\n\\n# Stop all arrays and containers\\nsudo mdadm --stop --scan\\n```\\n\\n### Removes the RAID metadata\\n\\nRemoves the RAID metadata on each **drive** and resets the **drive** to normal\\n\\n```sh\\nsudo mdadm --zero-superblock /dev/sda\\nsudo mdadm --zero-superblock /dev/sd[a-h]\\n```\\n\\n### [Optional] Remove RAID configuration\\n\\nRemove mount information to the array if exist. Edit the `/etc/fstab`:\\n\\n```sh title=\\"/etc/fstab\\"\\nsudo nano /etc/fstab\\n```\\n\\nAlso, remove the array definition if exist, from the `/etc/mdadm/mdadm.conf` file:\\n\\n```sh title=\\"/etc/mdadm/mdadm.conf\\"\\nsudo nano /etc/mdadm/mdadm.conf\\n```\\n\\n## Manage RAID Array with mdadm\\n\\n### Find all RAID arrays\\n\\n```sh\\n$ cat /proc/mdstat\\n\\nPersonalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10] \\nmd126 : active raid1 nvme0n1[1] nvme1n1[0]\\n      3800741888 blocks super external:/md127/0 [2/2] [UU]\\n      \\nmd127 : inactive nvme0n1[1](S) nvme1n1[0](S)\\n      10402 blocks super external:imsm\\n       \\nunused devices: <none>\\n```\\n\\n### Query information on a RAID array\\n\\n```sh\\nsudo mdadm --detail /dev/md0\\nsudo mdadm --query /dev/md0\\n```\\n\\n### Query information on a physical disk drive\\n\\n```sh\\nsudo mdadm --query /dev/sda\\nsudo mdadm --examine /dev/sda\\n```\\n\\n### Stop a RAID array\\n\\n```sh\\nsudo mdadm --stop /dev/md0\\n# Stop all arrays\\nsudo mdadm --stop --scan\\n```\\n\\n### Starting a RAID Array\\n\\n```sh\\n# This works if the array is defined in the configuration `/etc/mdadm/mdadm.conf` file.\\nsudo mdadm --assemble --scan\\nsudo mdadm --assemble /dev/md0\\n# If the array is not persisted in `/etc/mdadm/mdadm.conf` file but keeping RAID metadata\\nsudo mdadm --assemble /dev/md0 /dev/sda /dev/sdb\\n```\\n\\n### Adding spare devices to a RAID Array\\n\\n```sh\\nsudo mdadm /dev/md0 --add /dev/sde\\n```\\n\\n```sh\\n$ lsblk -f\\nNAME        FSTYPE          FSVER  LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINTS\\nloop0       squashfs        4.0                                                     0   100% /snap/core20/1974\\nloop1       squashfs        4.0                                                     0   100% /snap/lxd/24322\\nloop2       squashfs        4.0                                                     0   100% /snap/snapd/19457\\nsda         isw_raid_member 1.3.00                                                           \\nsdb         isw_raid_member 1.3.00                                                           \\nsdc         isw_raid_member 1.3.00                                                           \\nsdd         isw_raid_member 1.3.00                                                           \\nsde         isw_raid_member 1.3.00                                                           \\nsdf         isw_raid_member 1.3.00                                                           \\nsdg         isw_raid_member 1.3.00                                                           \\nsdh         isw_raid_member 1.3.00                                                           \\nnvme0n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                                                                                      \\nnvme1n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                         \\n```\\n\\n```sh\\nsudo fdisk -l /dev/sda\\n```\\n\\n### Delete partition and data in disk\\n\\n```sh\\nsudo dd if=/dev/zero of=/dev/sda  bs=512  count=1\\n```\\n\\n## References\\n\\n- [Linux VROC User Guide](https://www.intel.com/content/dam/support/us/en/documents/memory-and-storage/ssd-software/Linux_VROC_6-0_User_Guide.pdf)\\n- [VROC Ubuntu Setup](https://www.intel.com/content/dam/support/us/en/documents/memory-and-storage/ssd-software/VROC-Ubuntu-Setup-UserGuide-342787-US.pdf)"},{"id":"/raid-on-ubuntu","metadata":{"permalink":"/blog/raid-on-ubuntu","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/raid-on-ubuntu.mdx","source":"@site/../../blog/raid-on-ubuntu.mdx","title":"Managing RAID on ubuntu","description":"Setup Intel VROC RAID on Ubuntu","date":"2023-08-29T00:00:00.000Z","tags":[{"inline":true,"label":"raid","permalink":"/blog/tags/raid"},{"inline":true,"label":"ubuntu","permalink":"/blog/tags/ubuntu"}],"readingTime":6.825,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"description":"Setup Intel VROC RAID on Ubuntu","keywords":["Setup Intel VROC RAID on Ubuntu"],"image":"https://i.imgur.com/mErPwqL.png","tags":["raid","ubuntu"],"date":"2023-08-29T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Managing intel VROC RAID on ubuntu","permalink":"/blog/raid-intel-vroc"},"nextItem":{"title":"How to Work with CMake","permalink":"/blog/how-to-cmake"}},"content":"What is RAID?\\n\\nThe Redundant Array of Independent Disks, commonly known as RAID, is a technology used to combine multiple physical disk drives into a single logical unit for the purpose of data storage and performance improvement. \\n\\nThis blog will demonstrate to set up **software RAID** on Ubuntu(It should also work on other Linux).\\n\\n\x3c!-- truncate --\x3e\\n\\nTo setup **Intel VROC RAID** on Ubuntu, go to see: [Intel VROC RAID on Ubuntu](./raid-intel-vroc.mdx).\\n\\nThe hierarchy of storage abstraction layers in Linux.\\n\\n```plaintext\\n\\n    +------------------------+\\n    |   Application          |\\n    |                        |\\n    |open(\\"/mnt/media/1.png\\")|\\n    |                        |\\n    +------------------------+\\n\\n\\n\\n    +------------------------+\\n    |    Mount Point         |   Higher layer\\n    |                        |        ^\\n    |/dev/sda1 -> /mnt/media |        |\\n    |/dev/sda2 -> /mnt/file  |        |\\n    |                        |        |\\n    +------------------------+        |\\n                                      |\\n    +------------------------+        |\\n    |    Logical Volume      |        |\\n    |                        |        |\\n    | /dev/mapper/vg1-lg1,   |        |\\n    | /dev/mapper/vg1-lg2,   |        |\\n    +------------------------+        |\\n                                      |\\n    +------------------------+        |\\n    |     File System        |        |\\n    |                        |        |\\n    |   ext4, Btrfs, etc     |        |\\n    |                        |        |\\n    +------------------------+        |\\n                                      |\\n    +------------------------+        |\\n    |      Partition         |        |\\n    |                        |        |\\n    |  /dev/sda1, /dev/sda2  |        |\\n    |                        |        |\\n    +------------------------+        |\\n                                      |\\n                                      |\\n    +------------------------+        |\\n    |  Physical Disk Drive   |        |\\n    |                        |        |\\n    |    HDD /dev/hda        |  Lower layer\\n    |    SSD /dev/sda        |\\n    +------------------------+\\n```\\n\\nThe **RAID** is treated as **Logical Disk Drive** above the **Physical Disk Drive** layer. So you should do partitioning on it after being created.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nRecently, there is a chance for me to install Ubuntu(server) OS on a Dell Precision xxx workstation which is includes 2 NVMe SSDs and 8 SATA hard drives(HDDs) and has in-box hardware-assisted RAID controller(**Intel VROC**). In the past, I just play cloud virtual machines or personal host with single disk.\\n\\nConfiguring storage is a critical part of setting up a reliable workstation. So firstly, how to organize these following disks to their roles?\\n\\n- 2 SSDs hold the system to load quickly\\n- 8 HDDs store data persistently\\n\\nIn order to access these physical disks easily and reduce damages from data loss, I need to combine multiple disks to act as one, while keep data redundant and backup. After step-by-step research, there are some enterprise solutions present for me. These drive layer or file system layer approaches designed for specific purposes have their own advantages over others while they maybe achieve some same features.\\n\\nHere are some benefits and shortcomings of them alongside common use cases:\\n\\n- **RAID**(Redundant Array of Independent Disks)\\nAbstraction level: drive layer\\nConcept: RAID uses multiple drives to act as one(logical drive).\\nBenefits: improve data redundancy and data read/write performance\\n\\n- **LVM**(Logical Volume Management)\\nAbstraction level: file system layer\\nConcept: Manage a logical volume over multiple drives, each drive is a Physical Volume(PV).\\nBenefits: combine multiple disks into one logical volume, extend the volume with new disk added, increase/decrease mounted folder in file system\\n\\n- **ZFS**(Z File System)\\n\\nThere are three types of raid, as Wiki saying:\\n\\n1. hardware RAID\\n2. software RAID\\n   - **mdadm** in Linux\\n3. hardware-assisted software RAID, firmware RAID, fake RAID\\n   - **Intel VROC** (Virtual RAID on CPU)\\n\\nThis document will introduce how to set up software RAID(RAID0, RAID1, RAID5, RAID 10) on **already-installed** Ubuntu.\\n\\nTo create a RAID to hold the Ubuntu OS when installing Ubuntu, see [SoftwareRAID](https://help.ubuntu.com/community/Installation/SoftwareRAID) or [How to install Ubuntu with software RAID-1](https://www.servers.com/support/knowledge/linux-administration/how-to-install-ubuntu-with-software-raid-1)\\n\\nIn addition, there are different challenges you will face when installing Ubuntu Server and Ubuntu Desktop.\\n\\n> Install Ubuntu Server on RAID:\\n> Ubuntu Server Image has inbox `mdadm` utilities, so it is quite convenient to create the software RAID on multiple disks then install Ubuntu Server OS on the RAID in storage layer step during OS installation stage.\\n\\n---\\n\\n> Install Ubuntu Desktop on RAID:\\n> Ubuntu Desk Image does not ship the `mdadm` tool, so it is nearly impossible to create RAID and install Ubuntu Desktop OS on the RAID(however this one [Install Ubuntu 20.04 desktop with RAID 1 and LVM on machine with UEFI BIOS](https://askubuntu.com/questions/1299978/install-ubuntu-20-04-desktop-with-raid-1-and-lvm-on-machine-with-uefi-bios) from stackoverflow seems to be successful)\\n\\n## Set up RAID array\\n\\nTo create a RAID array ready to use in practice, there are always common steps:\\n\\n1. Create a RAID array(RAID 0, RAID 1, RAID 5 or RAID 10)\\n2. Mount the RAID array\\n3. Save the RAID array configuration for system boot\\n\\n### Create RAID array with mdadm\\n\\nCreate **RAID 0** array using devices: `/dev/sda` and `/dev/sdb`\\n\\n```sh\\nsudo mdadm --create --verbose /dev/md0 -l 0 -n 2 /dev/sda /dev/sdb\\n```\\n\\n### Mount RAID array for use\\n\\n1. Create a `ext4` filesystem on the array\\n\\n```sh\\nsudo mkfs.ext4 -F /dev/md0\\n```\\n\\n2. Mount the array\\n\\n```sh\\nsudo mkdir -p /mnt/md0\\n\\nsudo mount /dev/md0 /mnt/md0\\n```\\n\\n### Save RAID array configuration\\n\\nPersist the RAID array configuration to make the system reassemble and mount the RAID array automatically after reboot.\\n\\nAppend the line to `/etc/mdadm/mdadm.conf`:\\n\\n```sh\\nsudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf\\n```\\n\\nMake RAID array available in early boot stage:\\n\\n```sh\\nsudo update-initramfs -u\\n```\\n\\nPersist the mount point, edit `/etc/fstab`:\\n\\n```conf title=\\"/etc/fstab\\"\\n/dev/md0  /mnt/md0  ext4  defaults,nofail,discard 0 0\\n```\\n\\nor persist the mount point by using `UUID`, get `UUID` of the disk drive,\\n\\n```sh\\n$ blkid /dev/md124\\n/dev/md124: UUID=\\"b7fa44f2-0f05-47a1-b4ef-e9ad306898de\\" BLOCK_SIZE=\\"4096\\" TYPE=\\"ext4\\"\\n```\\n\\nthen edit in `/etc/fstab`,\\n\\n```conf title=\\"/etc/fstab\\"\\nUUID=b7fa44f2-0f05-47a1-b4ef-e9ad306898de  /volume  ext4  defaults,nofail,discard 0 0\\n```\\n\\nfinally apply the new mount,\\n\\n```sh\\nsudo mount -a\\n```\\n\\n## Delete RAID Array with mdadm\\n\\nMake sure to remove what are using the RAID array,\\n\\n[Optional] Umount the array from filesystem if mounted,\\n\\n```sh\\nsudo umount /dev/md0\\n```\\n\\nStop RAID array,\\n\\n```sh\\nsudo mdadm --stop /dev/md0\\n# Stop all arrays\\nsudo mdadm --stop --scan\\n```\\n\\nRemoves the RAID metadata and resets them to normal on the **Drives**,\\n\\n```sh\\nsudo mdadm --zero-superblock /dev/sda\\nsudo mdadm --zero-superblock /dev/sd[a-h]\\n```\\n\\n[Optional] Remove any persistent references to the array if exist. Edit the `/etc/fstab`:\\n\\n```sh title=\\"/etc/fstab\\"\\nsudo nano /etc/fstab\\n```\\n\\n[Optional] Also, remove the array definition if exist, from the `/etc/mdadm/mdadm.conf` file:\\n\\n```sh title=\\"/etc/mdadm/mdadm.conf\\"\\nsudo nano /etc/mdadm/mdadm.conf\\n```\\n\\n## Manage RAID Array with mdadm\\n\\n### Find the RAID arrays\\n\\n```sh\\n$ cat /proc/mdstat\\n\\nPersonalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10] \\nmd126 : active raid1 nvme0n1[1] nvme1n1[0]\\n      3800741888 blocks super external:/md127/0 [2/2] [UU]\\n      \\nmd127 : inactive nvme0n1[1](S) nvme1n1[0](S)\\n      10402 blocks super external:imsm\\n       \\nunused devices: <none>\\n```\\n\\n### Query information on RAID array\\n\\n```sh\\nsudo mdadm --detail /dev/md0\\nsudo mdadm --query /dev/md0\\n```\\n\\n### Query information on individual physical devices\\n\\n```sh\\nsudo mdadm --query /dev/sda\\nsudo mdadm --examine /dev/sda\\n```\\n\\n### Stop RAID array\\n\\n```sh\\nsudo mdadm --stop /dev/md0\\n# Stop all arrays\\nsudo mdadm --stop --scan\\n```\\n\\n### Start an RAID array\\n\\n```sh\\n# This works if the array is defined in the configuration `/etc/mdadm/mdadm.conf` file.\\nsudo mdadm --assemble --scan\\nsudo mdadm --assemble /dev/md0\\n# If the array is not persisted in `/etc/mdadm/mdadm.conf` file but keeping RAID metadata\\nsudo mdadm --assemble /dev/md0 /dev/sda /dev/sdb\\n```\\n\\n### Add a spare device to an RAID array\\n\\n```sh\\nsudo mdadm /dev/md0 --add /dev/sde\\n```\\n\\n### Check block devices\\n\\n```sh\\n$ lsblk -f\\nNAME        FSTYPE          FSVER  LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINTS\\nloop0       squashfs        4.0                                                     0   100% /snap/core20/1974\\nloop1       squashfs        4.0                                                     0   100% /snap/lxd/24322\\nloop2       squashfs        4.0                                                     0   100% /snap/snapd/19457\\nsda         isw_raid_member 1.3.00                                                           \\nsdb         isw_raid_member 1.3.00                                                           \\nsdc         isw_raid_member 1.3.00                                                           \\nsdd         isw_raid_member 1.3.00                                                           \\nsde         isw_raid_member 1.3.00                                                           \\nsdf         isw_raid_member 1.3.00                                                           \\nsdg         isw_raid_member 1.3.00                                                           \\nsdh         isw_raid_member 1.3.00                                                           \\nnvme0n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                                                                                      \\nnvme1n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                         \\n```\\n\\n### List UUID of devices\\n\\n```sh\\n$ sudo blkid\\n/dev/sdf: TYPE=\\"isw_raid_member\\"\\n/dev/nvme0n1: TYPE=\\"isw_raid_member\\"\\n/dev/sdd: TYPE=\\"isw_raid_member\\"\\n/dev/sdb: TYPE=\\"isw_raid_member\\"\\n/dev/sdg: TYPE=\\"isw_raid_member\\"\\n/dev/sde: TYPE=\\"isw_raid_member\\"\\n/dev/sdc: TYPE=\\"isw_raid_member\\"\\n/dev/md126p2: UUID=\\"ff1f3640-e590-486b-8570-c34dfd7bd1de\\" BLOCK_SIZE=\\"4096\\" TYPE=\\"ext4\\" PARTUUID=\\"07473e4a-9324-435d-9238-cf358cd9a6a9\\"\\n/dev/md126p1: UUID=\\"A636-3441\\" BLOCK_SIZE=\\"512\\" TYPE=\\"vfat\\" PARTUUID=\\"7eb27871-d9ad-4132-af06-7110948faf06\\"\\n/dev/nvme1n1: TYPE=\\"isw_raid_member\\"\\n/dev/sda: TYPE=\\"isw_raid_member\\"\\n/dev/md124: UUID=\\"b7fa44f2-0f05-47a1-b4ef-e9ad306898de\\" BLOCK_SIZE=\\"4096\\" TYPE=\\"ext4\\"\\n/dev/sdh: TYPE=\\"isw_raid_member\\"\\n/dev/loop1: TYPE=\\"squashfs\\"\\n/dev/loop4: TYPE=\\"squashfs\\"\\n/dev/loop2: TYPE=\\"squashfs\\"\\n/dev/loop0: TYPE=\\"squashfs\\"\\n/dev/loop3: TYPE=\\"squashfs\\"\\n```\\n\\n### Partition a disk\\n\\n```sh\\nsudo fdisk -l /dev/sda\\n```\\n\\n### Create filesystem on disk\\n\\n```sh\\nsudo mkfs.ext4 -F /dev/sda\\n```\\n\\n### Delete partition and data in disk\\n\\n```sh\\nsudo dd if=/dev/zero of=/dev/sda  bs=512  count=1\\n```\\n\\n## References\\n\\n[How To Create RAID Arrays with mdadm on Ubuntu 22.04  | DigitalOcean](https://www.digitalocean.com/community/tutorials/how-to-create-raid-arrays-with-mdadm-on-ubuntu-22-04)\\n\\n[SoftwareRAID](https://help.ubuntu.com/community/Installation/SoftwareRAID)\\n\\n[How to install Ubuntu with software RAID-1](https://www.servers.com/support/knowledge/linux-administration/how-to-install-ubuntu-with-software-raid-1)"},{"id":"/how-to-cmake","metadata":{"permalink":"/blog/how-to-cmake","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/how-to-cmake.mdx","source":"@site/../../blog/how-to-cmake.mdx","title":"How to Work with CMake","description":"How to work with CMake","date":"2023-06-25T00:00:00.000Z","tags":[{"inline":true,"label":"toolchain","permalink":"/blog/tags/toolchain"},{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"}],"readingTime":3.44,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"sidebar_label":"How to CMake","description":"How to work with CMake","keywords":["cmake","project structure"],"image":"https://i.imgur.com/mErPwqL.png","tags":["toolchain","how-to"],"date":"2023-06-25T00:00:00.000Z","authors":["frank"]},"unlisted":false,"prevItem":{"title":"Managing RAID on ubuntu","permalink":"/blog/raid-on-ubuntu"},"nextItem":{"title":"Configuring WiFi AutoSwitch in Windows","permalink":"/blog/configuring-wifi-autoswitch-in-windows"}},"content":"In brief, **CMake** is all about **targets** and **properties**\\n\\n\x3c!--truncate--\x3e\\n\\n## CMake Project Structure\\n\\nA typical **CMake** project can be regarded to has three `Tree`:\\n\\n**Source Tree**:\\n\\n```sh\\nproject_root\\n\u251c\u2500\u2500 CMakeLists.txt\\n\u251c\u2500\u2500 simple_example.cpp\\n\u251c\u2500\u2500 simple_lib.cpp\\n\u2514\u2500\u2500 simple_lib.hpp\\n```\\n\\n**Build Tree**:\\n\\n```sh\\nproject_root\\n\u251c\u2500\u2500 CMakeLists.txt\\n\u251c\u2500\u2500 simple_example.cpp\\n\u251c\u2500\u2500 simple_lib.cpp\\n\u251c\u2500\u2500 simple_lib.hpp\\n\u2514\u2500\u2500 build\\n    \u2514\u2500\u2500 CMakeCache.txt\\n```\\n\\n**Install Tree**:\\n\\nThis tree is located in the `CMAKE_INSTALL_PREFIX`, of which default value is platform-dependent. By default, it is set to `/usr/local` on Unix-like systems (Linux, macOS) and `C:/Program Files/<Project Name>` on Windows..\\n\\nTo change it, you can pass `-DCMAKE_INSTALL_PREFIX` argument during CMake `configuration` step, like this:\\n\\n```sh\\ncmake -B build -S . -DCMAKE_INSTALL_PREFIX=/my/custom/installation/path\\n```\\n\\nAlternatively, you can change it by passing `--prefix`(it can be relative path) argument during CMake `install` step, like this:\\n\\n```sh\\ncmake --install build --prefix \\"/my/custom/installation/path\\"\\n```\\n\\nIt\'s recommended to use a default install layout as `GNUInstallDirs`.\\n\\nA **install tree** will look like as below if you\'d like all things to be installed inside the project via `cmake --install build --prefix \\"./install`.\\n\\n```sh\\nproject_root\\n\u251c\u2500\u2500 CMakeLists.txt\\n\u251c\u2500\u2500 simple_example.cpp\\n\u251c\u2500\u2500 simple_lib.cpp\\n\u251c\u2500\u2500 simple_lib.hpp\\n\u251c\u2500\u2500 build\\n\u2502   \u2514\u2500\u2500 CMakeCache.txt\\n\u2514\u2500\u2500 install\\n    \u251c\u2500\u2500 bin\\n    \u2502   \u2514\u2500\u2500 executables\\n    \u251c\u2500\u2500 sbin\\n    \u2502   \u2514\u2500\u2500 sysadmin executables\\n    \u251c\u2500\u2500 lib\\n    \u2502   \u251c\u2500\u2500 compiled libraries (*.so (unix) or *.dll (windows))\\n    \u2502   \u2514\u2500\u2500 library archive files (*.lib (windows))\\n    \u251c\u2500\u2500 libexec\\n    \u2502   \u2514\u2500\u2500 executables not directly invoked by user\\n    \u251c\u2500\u2500 include\\n    \u2502   \u2514\u2500\u2500 header files\\n    \u2514\u2500\u2500 doc\\n       \u2514\u2500\u2500 documentation\\n```\\n\\n## How CMake Works\\n\\nA typical workflow of CMake includes `Configure`, `Build` and `Install` steps, combined with the above mentioned `Trees` concepts.\\n\\n1. `Configure` step will generate a sort of configuration files, the most important ones among them are `CMakeCache.txt`, `cmake_install.cmake` and `Makefile` if using `Make` as building system. With these generated configuration files, the later steps `Build` and `Install` will run according to them.\\n2. `Build` step will generate the build binary directory.\\n3. `Install` step will generate the install binary directory.\\n\\n## How to make your package be found by others by `find_package()`\\n\\npackage configuration files: `find_package`\\n\\n[Title](https://cmake.org/cmake/help/latest/guide/importing-exporting/index.html#importing-targets)\\n\\n## RPATH in CMake\\n\\n[^rpath]\\n\\n## CMake Variables\\n\\nThere are some useful and important CMake variables that will be introduced here:\\n\\n`CMAKE_PREFIX_PATH`\\n\\n`CMAKE_IGNORE_PATH`\\n\\n## `clang` FAQ\\n\\n### Find out `clang` include search path\\n\\n```sh\\n\u276f clang -x c -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /opt/homebrew/Cellar/llvm/17.0.1/lib/clang/17/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/System/Library/Frameworks (framework directory)\\nEnd of search list.\\n# 1 \\"/dev/null\\"\\n# 1 \\"<built-in>\\" 1\\n# 1 \\"<built-in>\\" 3\\n# 420 \\"<built-in>\\" 3\\n# 1 \\"<command line>\\" 1\\n# 1 \\"<built-in>\\" 2\\n# 1 \\"/dev/null\\" 2\\n```\\n\\n### Add include search path to `clang`\\n\\nUse environment variables `C_INCLUDE_PATH` for `c` and `CPLUS_INCLUDE_PATH` for `c++`.\\n\\n`clang`:\\n\\n```sh\\n\u276f C_INCLUDE_PATH=/opt/homebrew/include clang -x c -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /usr/local/include\\n /opt/homebrew/include\\n /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include\\n /Library/Developer/CommandLineTools/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)\\n```\\n\\n`clang++`:\\n\\n```sh\\n\u276f CPLUS_INCLUDE_PATH=/opt/homebrew/include clang -x c++ -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /usr/local/include\\n /opt/homebrew/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1\\n /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include\\n /Library/Developer/CommandLineTools/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)\\n```\\n\\nUse `-I` flag,\\n\\n```sh\\n\u276f clang -x c -I/opt/homebrew/include -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /opt/homebrew/include\\n /usr/local/include\\n /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include\\n /Library/Developer/CommandLineTools/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)\\n```\\n\\n### Find out `clang` library search paths\\n\\n```sh\\n\u276f clang -Xlinker -v\\n...\\nLibrary search paths:\\n\\t/usr/local/lib\\nFramework search paths:\\nld: Undefined symbols:\\n  _main, referenced from:\\n      <initial-undefines>\\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\\n```\\n\\n### Add library search path to `clang`\\n\\nUse environment variables `LIBRARY_PATH`,\\n\\n```sh\\n\u276f LIBRARY_PATH=$LIBRARY_PATH:/usr/lib clang -Xlinker -v\\n...\\nLibrary search paths:\\n\\t.\\n\\t/usr/lib\\n\\t/usr/local/lib\\nFramework search paths:\\nld: Undefined symbols:\\n  _main, referenced from:\\n      <initial-undefines>\\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\\n```\\n\\nUse `-L` flag:\\n\\n```sh\\n\u276f clang -L/opt/homebrew/lib -Xlinker -v\\n```\\n\\n[OS X clang include lib search path](https://langui.sh/2015/07/24/osx-clang-include-lib-search-paths/)\\n\\n## What is the difference? clang++ | clang -std=c++11\\n\\n## CMake FAQ\\n\\n### Add library search path to `CMake` globally in project\\n\\n1. `set(CMAKE_LIBRARY_PATH ${CMAKE_LIBRARY_PATH} /opt/local/lib)`\\n2. `LINK_DIRECTORIES(/opt/local/lib)`\\n\\n## References\\n\\n[CMake hands-on workshop \u2014 CMake Workshop](https://enccs.github.io/cmake-workshop/)\\n[^rpath]: [RPATH handling from official cmake](https://gitlab.kitware.com/cmake/community/-/wikis/doc/cmake/RPATH-handling)"},{"id":"/configuring-wifi-autoswitch-in-windows","metadata":{"permalink":"/blog/configuring-wifi-autoswitch-in-windows","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/configuring-wifi-autoswitch-in-windows.md","source":"@site/../../blog/configuring-wifi-autoswitch-in-windows.md","title":"Configuring WiFi AutoSwitch in Windows","description":"Configuring WiFi AutoSwitch Windows","date":"2023-06-01T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"},{"inline":true,"label":"network","permalink":"/blog/tags/network"},{"inline":true,"label":"windows","permalink":"/blog/tags/windows"}],"readingTime":0.87,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"sidebar_label":"Configuring WiFi AutoSwitch Windows","description":"Configuring WiFi AutoSwitch Windows","keywords":["autoswitch","wifi","windows"],"image":"https://i.imgur.com/mErPwqL.png","tags":["how-to","network","windows"],"date":"2023-06-01T00:00:00.000Z","authors":["frank"]},"unlisted":false,"prevItem":{"title":"How to Work with CMake","permalink":"/blog/how-to-cmake"},"nextItem":{"title":"Setting up Coral dev board","permalink":"/blog/setting-up-coral"}},"content":"If **autoSwitch** is turned on, it allows Windows to continue looking for other auto-connected wireless networks while connected to the current wireless network. If a higher priority auto-connected wireless network than the currently connected wireless network comes in range, Windows will automatically connect to it instead.\\n\\nIt also needs to work along with `priority` setting.\\n\\n\x3c!-- truncate --\x3e\\n\\nFor example:\\n\\nThere\'re 3 networks of profile name: `TP-Link-1`, `TP-Link-2` and `TP-Link-3`. PC(windows) will try to connect `TP-Link-3` if it\'s in range when it\'s already connected to `TP-Link-1` or `TP-Link-2`.\\n\\n1. Setup `autoswitch`:\\n\\n```sh\\nnetsh wlan set profileparameter name=\\"TP-Link-1\\" autoswitch=Yes\\nnetsh wlan set profileparameter name=\\"TP-Link-2\\" autoswitch=Yes\\nnetsh wlan set profileparameter name=\\"TP-Link-3\\" autoswitch=No\\n```\\n\\n2. Setup `priority`:\\n\\n```sh\\nnetsh wlan set profileorder name=\\"TP-Link-1\\" interface=\\"Wi-Fi\\" priority=3\\nnetsh wlan set profileorder name=\\"TP-Link-2\\" interface=\\"Wi-Fi\\" priority=2\\nnetsh wlan set profileorder name=\\"TP-Link-3\\" interface=\\"Wi-Fi\\" priority=1\\n```\\n\\nother tools:\\n\\nList profile name:\\n\\n```sh\\nnetsh wlan show profiles\\n```\\n\\nList connected WiFi:\\n\\n```sh\\nnetsh wlan show interfaces\\n```\\n\\n[Enable Auto Switch for Wireless Network Connection in Windows 10](https://winaero.com/enable-auto-switch-for-wireless-network-connection-in-windows-10/)\\n\\n[Change WiFi network priority in Windows 10](https://winaero.com/change-wifi-network-priority-in-windows-10/)"},{"id":"/setting-up-coral","metadata":{"permalink":"/blog/setting-up-coral","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/setting-up-coral.mdx","source":"@site/../../blog/setting-up-coral.mdx","title":"Setting up Coral dev board","description":"Setting up coral dev board","date":"2023-06-01T00:00:00.000Z","tags":[{"inline":true,"label":"how-to","permalink":"/blog/tags/how-to"},{"inline":true,"label":"network","permalink":"/blog/tags/network"},{"inline":true,"label":"environment","permalink":"/blog/tags/environment"}],"readingTime":2.075,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"sidebar_label":"Setting up coral dev board","description":"Setting up coral dev board","keywords":["autoswitch","wifi","windows"],"image":"https://i.imgur.com/mErPwqL.png","tags":["how-to","network","environment"],"date":"2023-06-01T00:00:00.000Z","authors":["frank"]},"unlisted":false,"prevItem":{"title":"Configuring WiFi AutoSwitch in Windows","permalink":"/blog/configuring-wifi-autoswitch-in-windows"},"nextItem":{"title":"Setting up a containerized dev environment VSCode","permalink":"/blog/preparing-dev-environment-in-vscode"}},"content":"Set up Coral Dev Board for employing an Edge TPU coprocessor.\\n\\nPrototype new projects demanding fast on-device inference for the ML models.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Background\\n\\nThe official documents [Get started with the Dev Board](https://coral.ai/docs/dev-board/get-started/) contains comprehensive how-to contents and rich examples. Here are just some experiences from myself. You can always go back to the official website to review and get the details.\\n\\nThe recommended method to access the Coral board is using [Mendel Development Tool (mdt)](https://coral.ai/docs/dev-board/mdt/), which is required to be installed on your host machine alongside the `Python`. Common steps to enter the shell terminal from `mdt` are in following:\\n\\n1. `mdt` tool generate a pair of `SSH key`s, save the `private key` on the host and push the `public key` to the Coral using `http` via `41337` port.\\n2. Coral board has a running a `mdt-keymaster` server that is listening `41337` port, and put the `public key` into `~/.ssh/authorized_keys`.\\n3. `mdt shell` now can login to the shell terminal of Coral board like `ssh mendel@192.168.100.2` when connecting over USB-C(OTG) or `ssh mendel@indigo-quill.local` over the same network where your host PC is.\\n\\n:::info\\nCoral board is set up by disabling password login in `OpenSSH` in default, so it must be provided with `SSH key` otherwise you change the setting to be like `PasswordAuthentication yes`.\\n:::\\n\\n:::note\\nYou can check the `key master` by,\\n\\n```sh\\nmendel@indigo-quill:~$ lsof -i:41337\\nCOMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\\nmdt-keyma 7846 mendel    5u  IPv4  20302      0t0  TCP 192.168.100.2:41337 (LISTEN)\\nmdt-keyma 7847 mendel    6u  IPv4  20619      0t0  TCP 192.168.101.2:41337 (LISTEN)\\n```\\n\\n:::\\n\\nAlthough `mdt` maybe facilitate the access to the Coral board, some magics and additional steps are kept from sight.\\n\\nTo do not use `mdt`, we need access the dev board through `serial console` instead of `mdt keymaster` server, to make configuration.\\n\\nThere are general ways to access a just-setup Coral in brief steps:\\n\\n1. Connect to Coral board\'s `serial console` by the instructions [Connect to the Dev Board\'s serial console](https://coral.ai/docs/dev-board/serial-console/)\\n2. Log into the Dev board by username: `mendel` and password: `mendel` in default.\\n3. Enable SSH Password Authentication. Edit `/etc/ssh/sshd_config` to change `PasswordAuthentication no` to `PasswordAuthentication yes`, and `sudo service ssh restart` to restart the ssh service.\\n4. Log into the shell using username: `mendel` and password: `mendel`.\\n5. If you want to keep the secure shell, generate `private SSH key` stored in host and `public SSH key` saved into Coral.\\n\\n## References\\n\\n- [Get started with the Dev Board | CoralCoralClose](https://coral.ai/docs/dev-board/get-started/)"},{"id":"/preparing-dev-environment-in-vscode","metadata":{"permalink":"/blog/preparing-dev-environment-in-vscode","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/main/_ssg/docusaurus/../../blog/preparing-dev-environment-in-vscode.mdx","source":"@site/../../blog/preparing-dev-environment-in-vscode.mdx","title":"Setting up a containerized dev environment VSCode","description":"Wiki Dev Environment","date":"2022-12-04T00:00:00.000Z","tags":[{"inline":true,"label":"dev","permalink":"/blog/tags/dev"},{"inline":true,"label":"docker","permalink":"/blog/tags/docker"}],"readingTime":1.57,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Backend & Applied ML Engineer","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank","page":null}],"frontMatter":{"authors":["frank"],"tags":["dev","docker"],"description":"Wiki Dev Environment","keywords":["dev environment","vscode","how-to"],"image":"https://i.imgur.com/mErPwqL.png","date":"2022-12-04T00:00:00.000Z","draft":false,"enableComments":true},"unlisted":false,"prevItem":{"title":"Setting up Coral dev board","permalink":"/blog/setting-up-coral"}},"content":"Here are some experiences that I have gotten to prepare a best-practice development environment for projects. I would like to update to keep up with the latest tech stacks.\\n\\n\x3c!-- truncate --\x3e\\n\\n## VS Code\\n\\nAs of now, the `VS Code` is the most popular IDE among developers. Absolutely, for me, it\'s my first choice and favorite developing tool.\\n\\n### Dev Container\\n\\n[Developing inside a Container using Visual Studio Code Remote Development](https://code.visualstudio.com/docs/devcontainers/containers)\\n\\nWhat is Dev Container?\\n\\nA \\"Dev Container\\" typically refers to a development environment that is containerized. Containers are lightweight, portable, and consistent environments that encapsulate an application and its dependencies. They provide a standardized way to package and run software across different environments, ensuring that the application behaves consistently regardless of where it is deployed.\\n\\nThe benefits of using Dev Containers include:\\n\\n1. Consistency: Developers work in the same environment, reducing the chances of environment-related issues.\\n2. Isolation: Dev Containers are isolated from the host system, preventing conflicts with other software installed on the developer\'s machine.\\n3. Reproducibility: The development environment can be easily recreated by anyone using the container specifications.\\n4. Portability: Dev Containers can be easily shared, allowing developers to work on the same project with minimal setup.\\n\\nBest ways to customize the environment in Dev containers?\\n\\n- [Using Images, Dockerfile, and Docker Compose](https://containers.dev/guide/dockerfile):love_you_gesture:\\n- [Using Features](https://containers.dev/features)\\n- [Using lifecycle scripts](https://containers.dev/implementors/json_reference/#lifecycle-scripts)\\n\\nHow to Write Dockerfile for Dev containers?\\n\\nYou can refer to this repo [GitHub - devcontainers/images: Repository for pre-built dev container images published under mcr.microsoft.com/devcontainers](https://github.com/devcontainers/images)\\n\\nWhat magics does the `Dev Containers` extension do when starting?\\n\\n1. Hook a default startup command `while sleep 1000; do :; done` to keep the container not exit. Disable this behavior by setting `overrideCommand: false`.\\n\\nHow to run a container inside of Dev containers?\\n\\n- [Docker-in-Docker](https://github.com/microsoft/vscode-dev-containers/tree/main/containers/docker-in-docker)\\n- [Docker-from-Docker](https://github.com/microsoft/vscode-dev-containers/tree/main/containers/docker-from-docker)\\n\\nFor instance, I use the **Docker-in-Docker** method to always test/run Docker containers inside of Dev containers."}]}}')}}]);