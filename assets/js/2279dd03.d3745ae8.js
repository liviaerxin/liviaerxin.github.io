"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6516],{13175:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>a});const l=JSON.parse('{"id":"practice/end-to-end-ml-deployment","title":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","description":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","source":"@site/../../docs/practice/end-to-end-ml-deployment.mdx","sourceDirName":"practice","slug":"/practice/end-to-end-ml-deployment","permalink":"/docs/practice/end-to-end-ml-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/docs/../../docs/practice/end-to-end-ml-deployment.mdx","tags":[{"inline":true,"label":"ml","permalink":"/docs/tags/ml"},{"inline":true,"label":"backend","permalink":"/docs/tags/backend"}],"version":"current","lastUpdatedBy":"frank","lastUpdatedAt":1746489600000,"frontMatter":{"sidebar_label":"End-to-End ML Deployment with MLflow, Docker, and FastAPI","description":"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker","keywords":["ml","mlops","mlflow"],"image":"https://i.imgur.com/mErPwqL.png","tags":["ml","backend"],"last_update":{"date":"2025-05-06T00:00:00.000Z","author":"frank"}},"sidebar":"docs","previous":{"title":"Code Snippet Management","permalink":"/docs/practice/code-snippet-management"},"next":{"title":"Lock Http Request","permalink":"/docs/practice/fastapi-best-practices"}}');var t=i(74848),o=i(28453);const r={sidebar_label:"End-to-End ML Deployment with MLflow, Docker, and FastAPI",description:"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker",keywords:["ml","mlops","mlflow"],image:"https://i.imgur.com/mErPwqL.png",tags:["ml","backend"],last_update:{date:new Date("2025-05-06T00:00:00.000Z"),author:"frank"}},s="Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker",d={},a=[{value:"Project Overview",id:"project-overview",level:2},{value:"Key Components",id:"key-components",level:2},{value:"MLflow",id:"mlflow",level:3},{value:"MinIO",id:"minio",level:3},{value:"FastAPI",id:"fastapi",level:3},{value:"Training and Registering a Model",id:"training-and-registering-a-model",level:3},{value:"Updating Models and Rolling Deployment",id:"updating-models-and-rolling-deployment",level:3},{value:"Conclusion",id:"conclusion",level:2}];function c(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"building-an-end-to-end-ml-deployment-pipeline-with-mlflow-fastapi-and-docker",children:"Building an End-to-End ML Deployment Pipeline with MLflow, FastAPI, and Docker"})}),"\n",(0,t.jsx)(n.p,{children:"Deploying machine learning models is more than just training \u2014 it\u2019s about tracking, versioning, serving, and monitoring. In this post, I\u2019ll walk you through how I built a production-ready ML pipeline using:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"MLflow"})," for experiment tracking and model registry"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"FastAPI"})," for serving models via REST API"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"MinIO"})," for artifact storage (S3-compatible)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Docker Compose"})," for orchestration"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,t.jsx)(n.strong,{children:"Full source code:"}),(0,t.jsx)(n.br,{}),"\n",(0,t.jsx)(n.a,{href:"https://github.com/liviaerxin/mlops-fastapi-mlflow-minio",children:"\ud83d\udd17 github.com/liviaerxin/mlops-fastapi-mlflow-minio"})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.p,{children:"\u2e3b"}),"\n",(0,t.jsx)(n.h2,{id:"project-overview",children:"Project Overview"}),"\n",(0,t.jsx)(n.p,{children:"This project provides:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["A structured pipeline to ",(0,t.jsx)(n.strong,{children:"log, register, and serve ML models"})]}),"\n",(0,t.jsxs)(n.li,{children:["Docker-based setup with ",(0,t.jsx)(n.strong,{children:"MLflow, FastAPI, and MinIO"})]}),"\n",(0,t.jsxs)(n.li,{children:["Simple ",(0,t.jsx)(n.strong,{children:"training"})," and ",(0,t.jsx)(n.strong,{children:"inference"})," workflows"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"\ud83d\udcc1 Project structure:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:".\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 inference-server/\n\u251c\u2500\u2500 mlflow-local-train-remote-register/\n\u251c\u2500\u2500 mlflow-server/\n\u251c\u2500\u2500 train.py\n\u2514\u2500\u2500 README.md\n"})}),"\n",(0,t.jsxs)(n.p,{children:["\ud83d\uddc2\ufe0f For full instructions, check the ",(0,t.jsx)(n.a,{href:"https://github.com/liviaerxin/mlops-fastapi-mlflow-minio/README.md",children:"README"})]}),"\n",(0,t.jsx)(n.h2,{id:"key-components",children:"Key Components"}),"\n",(0,t.jsx)(n.h3,{id:"mlflow",children:"MLflow"}),"\n",(0,t.jsx)(n.p,{children:"Handles:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Experiment tracking (",(0,t.jsx)(n.code,{children:"mlflow.log_param"}),", ",(0,t.jsx)(n.code,{children:"mlflow.log_metric"}),")"]}),"\n",(0,t.jsx)(n.li,{children:"Model registration and versioning"}),"\n",(0,t.jsxs)(n.li,{children:["Stage promotion (",(0,t.jsx)(n.code,{children:"Staging"}),", ",(0,t.jsx)(n.code,{children:"Production"}),")"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"minio",children:"MinIO"}),"\n",(0,t.jsx)(n.p,{children:"S3-compatible artifact store used by MLflow to save models."}),"\n",(0,t.jsx)(n.h3,{id:"fastapi",children:"FastAPI"}),"\n",(0,t.jsx)(n.p,{children:"Simple REST API to serve ML models loaded from the MLflow registry."}),"\n",(0,t.jsx)(n.p,{children:"Loads the remote model via:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:'mlflow.set_tracking_uri(os.environ.get("MLFLOW_SERVER", "http://127.0.0.1:5000"))\nmodel = mlflow.pyfunc.load_model(f"models:/{MODEL_NAME}/{MODEL_STAGE}")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"training-and-registering-a-model",children:"Training and Registering a Model"}),"\n",(0,t.jsx)(n.p,{children:"Remember: all these following operations are in local host and separate with the docker container environment!"}),"\n",(0,t.jsx)(n.p,{children:"Run the training script:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"python train.py\n"})}),"\n",(0,t.jsx)(n.p,{children:"Then log and register it to a remote MLflow server:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"python register-remote.py\n"})}),"\n",(0,t.jsx)(n.p,{children:"Key code snippet:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:'os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://127.0.0.1:9000" # Expose the minio via host 9000 port\nmlflow.set_tracking_uri("http://127.0.0.1:5001") # Expose the mlflow server via host 5001 port\nmi = mlflow.pytorch.log_model(model, artifact_path="model", registered_model_name=MODEL_NAME)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"updating-models-and-rolling-deployment",children:"Updating Models and Rolling Deployment"}),"\n",(0,t.jsx)(n.p,{children:"You can update models by:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Logging a new version to MLflow"}),"\n",(0,t.jsx)(n.li,{children:'Promoting it to "Production" stage'}),"\n",(0,t.jsx)(n.li,{children:"Using FastAPI logic to reload the latest version without downtime"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"You may also support blue-green deployments using Docker or Kubernetes."}),"\n",(0,t.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,t.jsx)(n.p,{children:"This setup gives you a scalable and reproducible ML deployment pipeline with clear separation of concerns:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"MLflow handles tracking and registry"}),"\n",(0,t.jsx)(n.li,{children:"MinIO manages artifact storage"}),"\n",(0,t.jsx)(n.li,{children:"FastAPI exposes inference endpoints"}),"\n",(0,t.jsx)(n.li,{children:"Docker Compose glues it all together"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"\u2e3b"}),"\n",(0,t.jsx)(n.p,{children:"\ud83d\udd17 GitHub Repo"}),"\n",(0,t.jsxs)(n.p,{children:["All code and instructions:\n",(0,t.jsx)(n.a,{href:"https://github.com/liviaerxin/mlops-fastapi-mlflow-minio",children:"\ud83d\udd17 github.com/liviaerxin/mlops-fastapi-mlflow-minio"})]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var l=i(96540);const t={},o=l.createContext(t);function r(e){const n=l.useContext(o);return l.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),l.createElement(o.Provider,{value:n},e.children)}}}]);